{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNH0oFgskaIwdKa2oQ6j96d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e93ea448f3784241b51e2a8567066b57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_017a462fdfc34ea3bafecc2d530773bb","IPY_MODEL_5c782495c895434fa284d6fc5e8d2f09","IPY_MODEL_c6178d4698d246c1ba8438d6c1e6413b"],"layout":"IPY_MODEL_4c4e8122e2a74295904e578197ae3cf7"}},"017a462fdfc34ea3bafecc2d530773bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db48a8c9c90b41b2a3ffac7ec75c9048","placeholder":"​","style":"IPY_MODEL_f170150817f54afa9f14437f8979a71f","value":"Fetching 1 files: 100%"}},"5c782495c895434fa284d6fc5e8d2f09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_36853b64cb974fa4a7e5c49109ccbefd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e43aa3ce774f4708a1542a5992b63a9e","value":1}},"c6178d4698d246c1ba8438d6c1e6413b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_576194f6c01e437b876c04efac558493","placeholder":"​","style":"IPY_MODEL_1f24af5f162042cbaa63358a5d786eae","value":" 1/1 [00:00&lt;00:00, 66.67it/s]"}},"4c4e8122e2a74295904e578197ae3cf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db48a8c9c90b41b2a3ffac7ec75c9048":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f170150817f54afa9f14437f8979a71f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36853b64cb974fa4a7e5c49109ccbefd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e43aa3ce774f4708a1542a5992b63a9e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"576194f6c01e437b876c04efac558493":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f24af5f162042cbaa63358a5d786eae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de793d7a670940968c86ccd0bb948717":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36b915e385b647b898606c5c1b81c328","IPY_MODEL_ecbebcdfba2d4b67af23937154da3671","IPY_MODEL_0cf6b8e8d9ae4e2095e0c2645171bc62"],"layout":"IPY_MODEL_8e1b70428ec94a4fabe866c7ff7ba49c"}},"36b915e385b647b898606c5c1b81c328":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fe8655da942462eb374a5579d02ffde","placeholder":"​","style":"IPY_MODEL_0b798b2e359f4e85b366c6d580f37359","value":"Fetching 1 files: 100%"}},"ecbebcdfba2d4b67af23937154da3671":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa1b86d181ce49149ed3abe56e1c64a8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bac669ba23b9471b9987d167875fc054","value":1}},"0cf6b8e8d9ae4e2095e0c2645171bc62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9386be75560b45619bdfa8bc7ecbd5db","placeholder":"​","style":"IPY_MODEL_c08c133c99a847f8b4f6f42f4a0cea94","value":" 1/1 [00:00&lt;00:00, 80.25it/s]"}},"8e1b70428ec94a4fabe866c7ff7ba49c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fe8655da942462eb374a5579d02ffde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b798b2e359f4e85b366c6d580f37359":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa1b86d181ce49149ed3abe56e1c64a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bac669ba23b9471b9987d167875fc054":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9386be75560b45619bdfa8bc7ecbd5db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c08c133c99a847f8b4f6f42f4a0cea94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"019a5fd1f07b4481b91a45cefd3758c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6cb5ef1bf7e04af8a46ac78b06907ad1","IPY_MODEL_55d602182c8e46ef9b97c37bba2a1db9","IPY_MODEL_b784fe5a71404637a66658f2472fdfae"],"layout":"IPY_MODEL_c74a08d74f914558afc44e29ff8c8407"}},"6cb5ef1bf7e04af8a46ac78b06907ad1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a584f0350344c76a8e165b6839b1600","placeholder":"​","style":"IPY_MODEL_3a0c7b5a1f784387a2236cdf35bde7e0","value":"Fetching 1 files: 100%"}},"55d602182c8e46ef9b97c37bba2a1db9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dca9dccd133443a7846997ac12b91c7f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b753e069af244dd3b976e66551220ebc","value":1}},"b784fe5a71404637a66658f2472fdfae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbd93927e8cf412d9bcbd5be9e863ea9","placeholder":"​","style":"IPY_MODEL_0c1f60cf678b451b84b859fb63b3fff6","value":" 1/1 [00:00&lt;00:00, 88.00it/s]"}},"c74a08d74f914558afc44e29ff8c8407":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a584f0350344c76a8e165b6839b1600":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a0c7b5a1f784387a2236cdf35bde7e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dca9dccd133443a7846997ac12b91c7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b753e069af244dd3b976e66551220ebc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbd93927e8cf412d9bcbd5be9e863ea9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c1f60cf678b451b84b859fb63b3fff6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jGD35Fy3Ibwv","executionInfo":{"status":"ok","timestamp":1757852091432,"user_tz":-300,"elapsed":35522,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"329a97e4-dfa5-4c9a-e147-38f804882964"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Проект: /content/drive/MyDrive/indrive_hack\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Папка проекта в Диске\n","PROJ = \"/content/drive/MyDrive/indrive_hack\"\n","import os\n","os.makedirs(PROJ, exist_ok=True)\n","os.makedirs(f\"{PROJ}/weights\", exist_ok=True)\n","print(\"Проект:\", PROJ)\n"]},{"cell_type":"code","source":["%pip install -q ultralytics gradio transformers Pillow torch torchvision\n","import os, zipfile\n","PROJ = \"/content/drive/MyDrive/indrive_hack\"\n","print(\"OK, libs ready. Project folder:\", PROJ)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLo9lSBMKB-4","executionInfo":{"status":"ok","timestamp":1757852228273,"user_tz":-300,"elapsed":10608,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"772ec7a2-91cf-4496-edcc-e4f47d9dfd7d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hOK, libs ready. Project folder: /content/drive/MyDrive/indrive_hack\n"]}]},{"cell_type":"code","source":["import os, zipfile\n","\n","PROJ = \"/content/drive/MyDrive/indrive_hack\"\n","os.makedirs(f\"{PROJ}/data_damage\", exist_ok=True)\n","os.makedirs(f\"{PROJ}/data_damage2\", exist_ok=True)\n","\n","def unzip_to(zip_path, dst):\n","    if not os.path.exists(zip_path):\n","        print(\"Файл не найден:\", zip_path)\n","        return\n","    with zipfile.ZipFile(zip_path, 'r') as z:\n","        z.extractall(dst)\n","    print(\"OK:\", os.path.basename(zip_path), \"→\", dst)\n","\n","unzip_to(f\"{PROJ}/Rust and Scrach.v1i.yolov8.zip\", f\"{PROJ}/data_damage\")\n","unzip_to(f\"{PROJ}/Car Scratch and Dent.v5i.yolov8.zip\", f\"{PROJ}/data_damage2\")\n","\n","print(\"YAML1:\", f\"{PROJ}/data_damage/data.yaml\")\n","print(\"YAML2:\", f\"{PROJ}/data_damage2/data.yaml\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rESS8cAfKMlU","executionInfo":{"status":"ok","timestamp":1757852275466,"user_tz":-300,"elapsed":16112,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"cb64a463-a008-4a62-aa04-4a3187cda0a9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["OK: Rust and Scrach.v1i.yolov8.zip → /content/drive/MyDrive/indrive_hack/data_damage\n","OK: Car Scratch and Dent.v5i.yolov8.zip → /content/drive/MyDrive/indrive_hack/data_damage2\n","YAML1: /content/drive/MyDrive/indrive_hack/data_damage/data.yaml\n","YAML2: /content/drive/MyDrive/indrive_hack/data_damage2/data.yaml\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","PROJ = \"/content/drive/MyDrive/indrive_hack\"\n","print(\"OK, подключен проект:\", PROJ)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_HwbSgfgKd-8","executionInfo":{"status":"ok","timestamp":1757852681230,"user_tz":-300,"elapsed":45772,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"cb06d976-be41-455c-dd58-1ae245558037"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","OK, подключен проект: /content/drive/MyDrive/indrive_hack\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=train \\\n","  model=yolov8s.pt \\\n","  data={PROJ}/data_damage/data.yaml \\\n","  imgsz=832 epochs=30 batch=16 patience=10 project={PROJ}/runs name=rust_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r96fduTGMhAg","executionInfo":{"status":"ok","timestamp":1757852877256,"user_tz":-300,"elapsed":122,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"04173c73-022f-4c0e-f15a-3890ef447fbd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: yolo: command not found\n"]}]},{"cell_type":"code","source":["# Установка (на всякий случай — тихо)\n","%pip install -q --upgrade ultralytics\n","\n","# Быстрые проверки\n","!python -m ultralytics --version\n","!python -m ultralytics help\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66XOFUC5NNC4","executionInfo":{"status":"ok","timestamp":1757853064642,"user_tz":-300,"elapsed":16383,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"b2c334d7-8cf9-4008-dd01-cb78d96e1072"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","/usr/bin/python3: No module named ultralytics.__main__; 'ultralytics' is a package and cannot be directly executed\n","/usr/bin/python3: No module named ultralytics.__main__; 'ultralytics' is a package and cannot be directly executed\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# просто проверка — загрузим пустую модель\n","YOLO(\"yolov8n.pt\")\n","print(\"✅ Ultralytics работает\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-8RE3UZNnIz","executionInfo":{"status":"ok","timestamp":1757853157591,"user_tz":-300,"elapsed":3162,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"d46a2112-d44e-4e87-91e1-755367df6b88"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 180.2MB/s 0.0s\n","✅ Ultralytics работает\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","PROJ = \"/content/drive/MyDrive/indrive_hack\"\n","\n","# создаём модель (yolov8s)\n","model = YOLO(\"yolov8s.pt\")\n","\n","# обучение\n","model.train(\n","    data=f\"{PROJ}/data_damage/data.yaml\",\n","    imgsz=832,\n","    epochs=30,\n","    batch=16,\n","    patience=10,\n","    project=f\"{PROJ}/runs\",\n","    name=\"rust_model\"\n",")\n","\n","# сохраняем лучший вес\n","!mkdir -p \"{PROJ}/weights\"\n","!cp \"{PROJ}/runs/detect/rust_model/weights/best.pt\" \"{PROJ}/weights/damage_rust.pt\"\n","!ls -lh \"{PROJ}/weights\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRCTNNGdNvyY","executionInfo":{"status":"ok","timestamp":1757853475269,"user_tz":-300,"elapsed":284261,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"76a65c7d-7ad0-4c7e-f155-97c7e603dacb"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ━━━━━━━━━━━━ 21.5MB 322.3MB/s 0.1s\n","Ultralytics 8.3.199 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/indrive_hack/data_damage/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=832, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=rust_model, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/indrive_hack/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/indrive_hack/runs/rust_model, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 105.0MB/s 0.0s\n","Overriding model.yaml nc=80 with nc=4\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2117596  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \n","Model summary: 129 layers, 11,137,148 parameters, 11,137,132 gradients, 28.7 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 171.6MB/s 0.0s\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 0.1±0.0 MB/s, size: 55.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/indrive_hack/data_damage/train/labels... 72 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 72/72 0.7it/s 1:46\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/indrive_hack/data_damage/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.8±0.4 ms, read: 0.0±0.0 MB/s, size: 33.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/indrive_hack/data_damage/valid/labels... 21 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 21/21 0.7it/s 28.7s\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/indrive_hack/data_damage/valid/labels.cache\n","Plotting labels to /content/drive/MyDrive/indrive_hack/runs/rust_model/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 832 train, 832 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/indrive_hack/runs/rust_model\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/30      5.93G      2.445      4.711      2.577         55        832: 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.8it/s 1.3s\n","                   all         21         32     0.0127      0.394      0.015    0.00921\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/30      6.33G      2.419      4.411      2.575         44        832: 100% ━━━━━━━━━━━━ 5/5 2.3it/s 2.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n","                   all         21         32      0.927      0.176      0.172       0.12\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/30      6.36G      2.174      3.451       2.34         26        832: 100% ━━━━━━━━━━━━ 5/5 2.0it/s 2.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.9it/s 1.2s\n","                   all         21         32      0.209      0.246      0.209      0.119\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/30       6.4G      1.931      2.836      2.123         30        832: 100% ━━━━━━━━━━━━ 5/5 2.4it/s 2.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n","                   all         21         32          1      0.175      0.188     0.0978\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/30      6.45G      2.151      2.939       2.26         73        832: 100% ━━━━━━━━━━━━ 5/5 2.3it/s 2.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n","                   all         21         32      0.949      0.176      0.178     0.0922\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/30      6.47G      2.089      2.819      2.141         82        832: 100% ━━━━━━━━━━━━ 5/5 2.4it/s 2.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n","                   all         21         32      0.727      0.162      0.184      0.117\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/30      6.52G      1.972      2.649      2.167         35        832: 100% ━━━━━━━━━━━━ 5/5 2.1it/s 2.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n","                   all         21         32      0.783      0.243      0.226      0.135\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/30      6.55G      2.024      2.611      2.163         80        832: 100% ━━━━━━━━━━━━ 5/5 2.4it/s 2.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n","                   all         21         32      0.515      0.275      0.231      0.108\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/30      6.59G      2.086       2.57      2.164         41        832: 100% ━━━━━━━━━━━━ 5/5 2.3it/s 2.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n","                   all         21         32      0.935      0.191      0.227     0.0865\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/30      6.62G      1.932      2.506      2.106         35        832: 100% ━━━━━━━━━━━━ 5/5 2.5it/s 2.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n","                   all         21         32      0.279      0.276      0.225     0.0753\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/30      6.66G      1.864      2.306      2.018         42        832: 100% ━━━━━━━━━━━━ 5/5 2.0it/s 2.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n","                   all         21         32      0.174      0.285      0.191     0.0901\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/30       6.7G      1.862       2.25      2.013         46        832: 100% ━━━━━━━━━━━━ 5/5 2.4it/s 2.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n","                   all         21         32      0.627      0.235      0.255      0.135\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/30      6.73G      1.918      2.305      2.071         45        832: 100% ━━━━━━━━━━━━ 5/5 2.4it/s 2.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n","                   all         21         32      0.323      0.247      0.266      0.133\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/30      6.77G      1.859      2.153      2.021         57        832: 100% ━━━━━━━━━━━━ 5/5 2.4it/s 2.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n","                   all         21         32      0.589      0.298      0.265      0.137\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/30      6.81G      1.971      2.392      2.068         80        832: 100% ━━━━━━━━━━━━ 5/5 2.0it/s 2.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n","                   all         21         32      0.247      0.197      0.205      0.114\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/30      6.85G      1.832      2.138      2.008         60        832: 100% ━━━━━━━━━━━━ 5/5 2.4it/s 2.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n","                   all         21         32      0.499      0.239      0.222      0.133\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/30      6.88G      1.789      2.209      1.925         46        832: 100% ━━━━━━━━━━━━ 5/5 2.2it/s 2.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n","                   all         21         32       0.53      0.148       0.19     0.0961\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/30      6.92G      1.734      2.132      1.958         13        832: 100% ━━━━━━━━━━━━ 5/5 2.3it/s 2.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n","                   all         21         32       0.41      0.258      0.176     0.0642\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/30      6.95G      1.662      1.954      1.882         62        832: 100% ━━━━━━━━━━━━ 5/5 2.1it/s 2.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n","                   all         21         32      0.678      0.224      0.245      0.119\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/30      6.99G      1.714      2.092      1.914         31        832: 100% ━━━━━━━━━━━━ 5/5 2.3it/s 2.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n","                   all         21         32      0.287      0.358      0.307      0.159\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/30      7.02G      1.781      2.409       2.09         57        832: 100% ━━━━━━━━━━━━ 5/5 1.4it/s 3.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n","                   all         21         32      0.272      0.321      0.296      0.164\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/30      7.22G      1.746      2.307      2.036         27        832: 100% ━━━━━━━━━━━━ 5/5 2.2it/s 2.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.4s\n","                   all         21         32      0.342      0.246       0.27      0.156\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/30      7.25G      1.734      2.148      2.073         21        832: 100% ━━━━━━━━━━━━ 5/5 2.4it/s 2.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n","                   all         21         32      0.567      0.252       0.28      0.163\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/30      7.29G      1.709      1.983      2.025         62        832: 100% ━━━━━━━━━━━━ 5/5 2.3it/s 2.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n","                   all         21         32      0.269      0.373      0.286       0.17\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/30      7.32G      1.681      1.973      2.046         54        832: 100% ━━━━━━━━━━━━ 5/5 2.4it/s 2.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4it/s 0.3s\n","                   all         21         32      0.297      0.362      0.307      0.174\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/30      7.36G      1.537      1.866      1.871          9        832: 100% ━━━━━━━━━━━━ 5/5 2.3it/s 2.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n","                   all         21         32      0.591       0.34      0.298      0.171\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/30      6.35G      1.511      1.849      1.892         13        832: 100% ━━━━━━━━━━━━ 5/5 2.5it/s 2.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n","                   all         21         32      0.363      0.387       0.32      0.181\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/30      6.71G      1.553      1.759      1.881         33        832: 100% ━━━━━━━━━━━━ 5/5 2.5it/s 2.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n","                   all         21         32      0.343      0.416      0.306      0.175\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/30      6.71G      1.561      1.727      1.915         58        832: 100% ━━━━━━━━━━━━ 5/5 2.5it/s 2.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n","                   all         21         32      0.565      0.402      0.298      0.173\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/30      6.71G      1.461      1.624      1.853         58        832: 100% ━━━━━━━━━━━━ 5/5 2.1it/s 2.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n","                   all         21         32      0.562       0.37      0.326      0.176\n","\n","30 epochs completed in 0.032 hours.\n","Optimizer stripped from /content/drive/MyDrive/indrive_hack/runs/rust_model/weights/last.pt, 22.6MB\n","Optimizer stripped from /content/drive/MyDrive/indrive_hack/runs/rust_model/weights/best.pt, 22.6MB\n","\n","Validating /content/drive/MyDrive/indrive_hack/runs/rust_model/weights/best.pt...\n","Ultralytics 8.3.199 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 72 layers, 11,127,132 parameters, 0 gradients, 28.4 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.4s\n","                   all         21         32      0.362      0.387      0.327      0.182\n","                   car         12         17          1      0.763        0.9      0.584\n","                  dunt          5          7     0.0621      0.286     0.0903     0.0336\n","                  rust          3          6      0.387        0.5      0.311       0.11\n","               scracth          2          2          0          0    0.00634   0.000858\n","Speed: 0.3ms preprocess, 10.5ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/indrive_hack/runs/rust_model\u001b[0m\n","cp: cannot stat '/content/drive/MyDrive/indrive_hack/runs/detect/rust_model/weights/best.pt': No such file or directory\n","total 0\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","PROJ = \"/content/drive/MyDrive/indrive_hack\"\n","\n","model = YOLO(\"yolov8s.pt\")\n","\n","model.train(\n","    data=f\"{PROJ}/data_damage2/data.yaml\",\n","    imgsz=832,\n","    epochs=60,\n","    batch=16,\n","    patience=15,\n","    project=f\"{PROJ}/runs\",\n","    name=\"damage_model\"\n",")\n","\n","!mkdir -p \"{PROJ}/weights\"\n","!cp \"{PROJ}/runs/detect/damage_model/weights/best.pt\" \"{PROJ}/weights/damage_v2.pt\"\n","!ls -lh \"{PROJ}/weights\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7j6jadGO5WT","executionInfo":{"status":"ok","timestamp":1757855113475,"user_tz":-300,"elapsed":1617408,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"53d0b64a-96ba-48ca-ba89-af9e3244afce"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.199 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/indrive_hack/data_damage2/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=832, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=damage_model, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/indrive_hack/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/indrive_hack/runs/damage_model, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=3\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n","Model summary: 129 layers, 11,136,761 parameters, 11,136,745 gradients, 28.7 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.9±0.5 ms, read: 0.1±0.0 MB/s, size: 68.2 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/indrive_hack/data_damage2/train/labels... 585 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 585/585 1.3it/s 7:42\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/indrive_hack/data_damage2/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.8±0.7 ms, read: 0.1±0.0 MB/s, size: 70.9 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/indrive_hack/data_damage2/valid/labels... 20 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 20/20 0.8it/s 26.5s\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/indrive_hack/data_damage2/valid/labels.cache\n","Plotting labels to /content/drive/MyDrive/indrive_hack/runs/damage_model/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 832 train, 832 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/indrive_hack/runs/damage_model\u001b[0m\n","Starting training for 60 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/60       6.1G      2.099      4.183      2.304         25        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 24.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1it/s 0.9s\n","                   all         20         27      0.395     0.0833      0.033    0.00705\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/60      6.46G      2.113      3.169      2.354         25        832: 100% ━━━━━━━━━━━━ 37/37 1.8it/s 20.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0it/s 0.5s\n","                   all         20         27      0.337      0.222    0.00354   0.000949\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/60      6.51G      2.152      3.233      2.428         29        832: 100% ━━━━━━━━━━━━ 37/37 1.7it/s 22.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n","                   all         20         27    0.00833     0.0417     0.0043     0.0016\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/60      6.54G      2.169       3.27      2.454         30        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 23.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0it/s 0.5s\n","                   all         20         27    0.00196     0.0417    0.00127   0.000454\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/60      6.58G      2.149      3.265      2.464         40        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 24.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n","                   all         20         27      0.359     0.0185     0.0321     0.0098\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/60      6.62G        2.1      3.187      2.416         27        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 24.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n","                   all         20         27     0.0271      0.037     0.0213    0.00503\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/60      6.65G      2.064      3.157      2.406         21        832: 100% ━━━━━━━━━━━━ 37/37 1.7it/s 22.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n","                   all         20         27     0.0185     0.0185    0.00609     0.0018\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/60      6.68G      2.016      3.127      2.367         25        832: 100% ━━━━━━━━━━━━ 37/37 1.4it/s 25.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n","                   all         20         27     0.0171      0.125     0.0186    0.00403\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/60      6.72G      2.001      3.073      2.366         38        832: 100% ━━━━━━━━━━━━ 37/37 1.7it/s 22.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n","                   all         20         27      0.394      0.125     0.0539     0.0161\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/60      6.76G      1.989      2.995      2.328         30        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 23.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n","                   all         20         27      0.347     0.0185     0.0128    0.00488\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/60       6.8G      2.001      3.024      2.321         20        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 23.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n","                   all         20         27      0.379       0.12     0.0489     0.0179\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/60      6.83G      1.905      2.895      2.222         25        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 24.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0it/s 0.5s\n","                   all         20         27      0.597      0.157      0.121     0.0365\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/60      6.87G        1.9       2.84      2.232         19        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 24.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n","                   all         20         27      0.451     0.0787      0.111     0.0374\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/60      6.91G      1.832      2.762      2.201         34        832: 100% ━━━━━━━━━━━━ 37/37 1.4it/s 25.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n","                   all         20         27       0.43      0.199     0.0714     0.0171\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/60      6.95G      1.836      2.702      2.172         33        832: 100% ━━━━━━━━━━━━ 37/37 1.7it/s 22.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n","                   all         20         27      0.501       0.18      0.146     0.0699\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/60      6.97G       1.86      2.684      2.148         30        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 24.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n","                   all         20         27      0.464      0.199      0.167     0.0689\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/60      7.02G      1.799      2.668      2.119         30        832: 100% ━━━━━━━━━━━━ 37/37 1.7it/s 22.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n","                   all         20         27      0.406      0.098     0.0677     0.0238\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/60      7.05G      1.811      2.666      2.146         22        832: 100% ━━━━━━━━━━━━ 37/37 1.7it/s 22.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n","                   all         20         27      0.487      0.153      0.159     0.0652\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/60      7.09G       1.77       2.56      2.082         24        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 23.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n","                   all         20         27      0.479      0.208       0.16     0.0663\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/60      7.12G      1.761       2.49      2.084         20        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 23.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n","                   all         20         27      0.475      0.157      0.142     0.0405\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/60      7.16G      1.764      2.482      2.082         27        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 22.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0it/s 0.5s\n","                   all         20         27      0.539      0.252      0.164     0.0507\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/60       7.2G      1.713      2.454      2.048         26        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 22.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n","                   all         20         27      0.906      0.243      0.312      0.124\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/60      7.23G      1.678      2.347      2.017         30        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 24.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n","                   all         20         27       0.55      0.241      0.181     0.0772\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/60      7.27G      1.686      2.382      2.029         20        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 23.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n","                   all         20         27      0.581      0.181      0.185     0.0699\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/60      7.31G      1.648      2.309      2.001         31        832: 100% ━━━━━━━━━━━━ 37/37 1.7it/s 21.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n","                   all         20         27      0.533      0.253      0.303     0.0939\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/60      7.85G      1.621      2.231      1.967         22        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 23.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n","                   all         20         27      0.674      0.199      0.228      0.094\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/60       6.3G      1.647      2.229      1.967         24        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 23.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n","                   all         20         27      0.569      0.241      0.485      0.127\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/60       6.3G      1.619      2.162      1.932         24        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 24.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0it/s 0.5s\n","                   all         20         27      0.459       0.65      0.526      0.224\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/60       6.3G      1.596      2.129      1.934         20        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 22.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n","                   all         20         27       0.52      0.611      0.578      0.271\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/60       6.3G      1.577      2.082      1.893         20        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 24.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n","                   all         20         27      0.359       0.69      0.525      0.148\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      31/60       6.3G      1.558      2.041      1.878         30        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 23.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n","                   all         20         27      0.745      0.158      0.244     0.0957\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      32/60       6.3G      1.532      1.983      1.849         19        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 23.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n","                   all         20         27      0.487      0.213      0.171     0.0717\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      33/60       6.3G      1.528      2.031      1.876         25        832: 100% ━━━━━━━━━━━━ 37/37 1.7it/s 21.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n","                   all         20         27      0.524      0.241      0.247      0.105\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      34/60      6.32G       1.51      1.933      1.856         19        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 23.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n","                   all         20         27      0.589      0.176      0.249      0.113\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      35/60      6.36G      1.477      1.916       1.82         21        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 23.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n","                   all         20         27      0.731      0.217      0.315      0.143\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      36/60      6.39G      1.479       1.92      1.813         35        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 22.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n","                   all         20         27      0.639      0.507      0.546      0.196\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      37/60      6.43G      1.426      1.809      1.753         40        832: 100% ━━━━━━━━━━━━ 37/37 1.7it/s 22.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n","                   all         20         27      0.556      0.259      0.236     0.0894\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      38/60      6.47G      1.434       1.82      1.781         15        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 23.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n","                   all         20         27      0.532      0.611      0.603      0.183\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      39/60       6.5G      1.423      1.734      1.789         26        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 22.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0it/s 0.5s\n","                   all         20         27      0.391      0.792      0.608      0.197\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      40/60      6.53G      1.394      1.765      1.763         20        832: 100% ━━━━━━━━━━━━ 37/37 1.7it/s 22.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n","                   all         20         27      0.578      0.611      0.618      0.198\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      41/60      6.58G      1.379      1.656      1.719         29        832: 100% ━━━━━━━━━━━━ 37/37 1.5it/s 25.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n","                   all         20         27      0.846      0.513      0.619      0.232\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      42/60      6.61G      1.347      1.634      1.701         19        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 22.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n","                   all         20         27       0.36      0.611       0.59      0.195\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      43/60      6.65G      1.362      1.684      1.713         27        832: 100% ━━━━━━━━━━━━ 37/37 1.6it/s 22.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n","                   all         20         27      0.695      0.218      0.415      0.143\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      44/60      6.93G      1.324       1.58      1.678         38        832: 100% ━━━━━━━━━━━━ 37/37 1.7it/s 21.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n","                   all         20         27      0.232      0.588      0.534      0.237\n","\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 29, best model saved as best.pt.\n","To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n","\n","44 epochs completed in 0.307 hours.\n","Optimizer stripped from /content/drive/MyDrive/indrive_hack/runs/damage_model/weights/last.pt, 22.6MB\n","Optimizer stripped from /content/drive/MyDrive/indrive_hack/runs/damage_model/weights/best.pt, 22.6MB\n","\n","Validating /content/drive/MyDrive/indrive_hack/runs/damage_model/weights/best.pt...\n","Ultralytics 8.3.199 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 72 layers, 11,126,745 parameters, 0 gradients, 28.4 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n","                   all         20         27      0.522      0.611      0.578      0.272\n","                  dent          7          8      0.455        0.5      0.537      0.247\n","                  dirt          1          1      0.865          1      0.995      0.497\n","               scratch         13         18      0.247      0.333      0.204     0.0701\n","Speed: 1.0ms preprocess, 10.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/indrive_hack/runs/damage_model\u001b[0m\n","cp: cannot stat '/content/drive/MyDrive/indrive_hack/runs/detect/damage_model/weights/best.pt': No such file or directory\n","total 0\n"]}]},{"cell_type":"code","source":["!ls -lh /content/drive/MyDrive/indrive_hack/runs/rust_model/weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZSylJAu7QG4h","executionInfo":{"status":"ok","timestamp":1757855113833,"user_tz":-300,"elapsed":297,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"e0e3c463-2ab6-46a6-fc51-a092137798c3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["total 44M\n","-rw------- 1 root root 22M Sep 14 12:37 best.pt\n","-rw------- 1 root root 22M Sep 14 12:37 last.pt\n"]}]},{"cell_type":"code","source":["!mkdir -p /content/drive/MyDrive/indrive_hack/weights\n","!cp /content/drive/MyDrive/indrive_hack/runs/rust_model/weights/best.pt \\\n","    /content/drive/MyDrive/indrive_hack/weights/damage_rust.pt\n","!ls -lh /content/drive/MyDrive/indrive_hack/weights\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YjZEPuvEV9bR","executionInfo":{"status":"ok","timestamp":1757855343260,"user_tz":-300,"elapsed":586,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"738ec55c-1192-4cd3-8515-aa015c67f913"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["total 22M\n","-rw------- 1 root root 22M Sep 14 13:09 damage_rust.pt\n"]}]},{"cell_type":"code","source":["!rm -rf /content/weights\n","!ln -s /content/drive/MyDrive/indrive_hack/weights /content/weights\n","!ls -lh /content/weights\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fx8ogpsuV--M","executionInfo":{"status":"ok","timestamp":1757855352402,"user_tz":-300,"elapsed":325,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"e80edc0f-52ab-4191-e814-870cf713add5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["lrwxrwxrwx 1 root root 43 Sep 14 13:09 /content/weights -> /content/drive/MyDrive/indrive_hack/weights\n"]}]},{"cell_type":"code","source":["# скопировать лучшие веса второй модели\n","!cp /content/drive/MyDrive/indrive_hack/runs/damage_model/weights/best.pt \\\n","    /content/drive/MyDrive/indrive_hack/weights/damage_v2.pt\n","\n","# (если раньше делали симлинк /content/weights, он уже указывает на папку выше)\n","!ls -lh /content/drive/MyDrive/indrive_hack/weights\n","!ls -lh /content/weights\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYQZMwFtXooM","executionInfo":{"status":"ok","timestamp":1757855782111,"user_tz":-300,"elapsed":324,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"56c99fbe-4406-4ce9-8afc-46ed3e690b92"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["total 44M\n","-rw------- 1 root root 22M Sep 14 13:09 damage_rust.pt\n","-rw------- 1 root root 22M Sep 14 13:16 damage_v2.pt\n","lrwxrwxrwx 1 root root 43 Sep 14 13:09 /content/weights -> /content/drive/MyDrive/indrive_hack/weights\n"]}]},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/indrive_hack/theme.css\n",".gradio-container {max-width: 1200px;}\n","h1.title {margin: 6px 0 12px}\n",".card {background:#0b1220;border:1px solid #1f2937;border-radius:10px;padding:14px}\n",".badges {display:flex;flex-wrap:wrap;gap:6px;margin-top:6px}\n",".badge {padding:4px 8px;border-radius:999px;font-size:12px;border:1px solid #243244}\n",".badge.scratch {background:#0b2447;color:#8ecbff;border-color:#1d3b63}\n",".badge.dent    {background:#2a1630;color:#ffb3d2;border-color:#482547}\n",".badge.rust    {background:#2a1f0e;color:#ffc792;border-color:#4b3318}\n",".badge.dirt    {background:#122416;color:#b7e4c7;border-color:#234a2c}\n",".badge.qf      {background:#261a1a;color:#ffb4b4;border-color:#3f2a2a}\n",".meter {height:14px;border-radius:8px;background:#1f2937;overflow:hidden}\n",".meter > div {height:100%;background:linear-gradient(90deg,#22c55e,#f59e0b,#ef4444)}\n",".thumb-row {display:flex;gap:8px;flex-wrap:wrap;margin-top:8px}\n",".thumb-row img {height:72px;border:1px solid #2b3648;border-radius:6px}\n",".small {font-size:12px;color:#94a3b8}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYWAZC84YY9S","executionInfo":{"status":"ok","timestamp":1757855981909,"user_tz":-300,"elapsed":143,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"bf993e3d-615a-4a47-9db9-501d25aede86"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing /content/drive/MyDrive/indrive_hack/theme.css\n"]}]},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/indrive_hack/app.py\n","import os, io, json, zipfile, time\n","import gradio as gr\n","from PIL import Image, ImageDraw\n","import numpy as np\n","import torch\n","from transformers import CLIPProcessor, CLIPModel\n","\n","WEI = \"/content/drive/MyDrive/indrive_hack/weights\"\n","CSS = \"/content/drive/MyDrive/indrive_hack/theme.css\"\n","\n","# YOLO для кропа\n","crop_yolo = None\n","try:\n","    from ultralytics import YOLO\n","    crop_yolo = YOLO(\"yolov8n.pt\")\n","except Exception:\n","    crop_yolo = None\n","\n","# damage модели\n","damage_yolo = None\n","damage_yolo_v2 = None\n","damage_names = None\n","try:\n","    from ultralytics import YOLO\n","    p1 = os.path.join(WEI, \"damage_rust.pt\")\n","    p2 = os.path.join(WEI, \"damage_v2.pt\")\n","    if os.path.exists(p1):\n","        damage_yolo = YOLO(p1)\n","        try:\n","            damage_names = damage_yolo.model.names if hasattr(damage_yolo, \"model\") else damage_yolo.names\n","        except Exception:\n","            damage_names = None\n","    if os.path.exists(p2):\n","        damage_yolo_v2 = YOLO(p2)\n","except Exception:\n","    pass\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n","clip_proc  = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","RU_LABEL = {\"scratch\":\"царапина\",\"dent\":\"вмятина\",\"rust\":\"ржавчина\",\"dirt\":\"грязь/пятно\",\"damage\":\"повреждение\"}\n","EN_LABEL = {\"scratch\":\"scratch\",\"dent\":\"dent\",\"rust\":\"rust\",\"dirt\":\"dirt\",\"damage\":\"damage\"}\n","COLOR = {\"scratch\":(66,165,245),\"dent\":(244,143,177),\"rust\":(255,171,64),\"dirt\":(129,199,132),\"damage\":(0,200,255)}\n","\n","def draw_label(draw, box, text):\n","    x1,y1,x2,y2 = box\n","    draw.rectangle([x1, y1-16, x1+8+6*len(text), y1], fill=(0,0,0,160))\n","    draw.text((x1+4, y1-14), text, fill=(255,255,255))\n","\n","def normalize_label(s):\n","    if not s: return \"damage\"\n","    s = str(s).lower()\n","    if \"scr\" in s: return \"scratch\"\n","    if \"dent\" in s or \"dunt\" in s: return \"dent\"\n","    if \"rust\" in s: return \"rust\"\n","    if \"dirt\" in s: return \"dirt\"\n","    return s\n","\n","def crop_car(img: Image.Image) -> Image.Image:\n","    if crop_yolo is None: return img\n","    res = crop_yolo.predict(source=img, imgsz=640, conf=0.25, verbose=False)\n","    if not res: return img\n","    best_area, best_box = 0, None\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            try:\n","                if int(b.cls.item()) != 2:  # COCO \"car\"\n","                    continue\n","                x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","                area = (x2-x1)*(y2-y1)\n","                if area > best_area:\n","                    best_area, best_box = area, (x1,y1,x2,y2)\n","            except: pass\n","    if best_box is None: return img\n","    x1,y1,x2,y2 = best_box\n","    x1=max(0,x1); y1=max(0,y1); x2=min(img.width,x2); y2=min(img.height,y2)\n","    return img.crop((x1,y1,x2,y2)) if x2>x1 and y2>y1 else img\n","\n","@torch.no_grad()\n","def clip_cleanliness(img: Image.Image):\n","    texts = [\"a clean car photo\",\"a dirty, muddy car photo\"]\n","    inputs = clip_proc(text=texts, images=img, return_tensors=\"pt\", padding=True).to(device)\n","    probs = clip_model(**inputs).logits_per_image[0].softmax(dim=0).detach().cpu().numpy()\n","    return {\"clean\": float(probs[0]), \"dirty\": float(probs[1])}\n","\n","def quality_flags(img: Image.Image):\n","    arr = np.array(img.convert(\"L\"))\n","    bright = arr.mean(); contrast = arr.std()\n","    pad = np.pad(arr, 1, mode=\"edge\")\n","    lap = (pad[:-2,1:-1] + pad[2:,1:-1] + pad[1:-1,:-2] + pad[1:-1,2:] - 4*arr)\n","    sharp = float(lap.var())\n","    flags = []\n","    if bright < 70:  flags.append((\"low_light\",\"Низкая освещённость\"))\n","    if bright > 200: flags.append((\"overexp\",\"Пересвет\"))\n","    if contrast < 20:flags.append((\"low_contrast\",\"Низкий контраст\"))\n","    if sharp < 80:   flags.append((\"blurry\",\"Размыто\"))\n","    return flags, dict(bright=round(float(bright),1), contrast=round(float(contrast),1), sharp=round(sharp,1))\n","\n","def run_detector(detector, img: Image.Image, conf_thr=0.35, names_map=None):\n","    if detector is None: return []\n","    res = detector.predict(source=img, imgsz=640, conf=conf_thr, verbose=False)\n","    out = []\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","            score = float(b.conf.item())\n","            cls_id = int(b.cls.item()) if hasattr(b, \"cls\") else -1\n","            raw_name = names_map.get(cls_id, str(cls_id)) if isinstance(names_map, dict) else None\n","            out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"raw_name\": raw_name})\n","    return out\n","\n","def detect_damage(img: Image.Image, conf_thr=0.35, lang=\"ru\"):\n","    boxes_all = []\n","    boxes_all += run_detector(damage_yolo, img, conf_thr, names_map=damage_names)\n","    boxes_all += run_detector(damage_yolo_v2, img, conf_thr, names_map=None)\n","\n","    vis = img.copy()\n","    draw = ImageDraw.Draw(vis)\n","    out = []\n","    thumbs = []\n","    for b in boxes_all:\n","        x1,y1,x2,y2 = b[\"xyxy\"]; score = b[\"score\"]\n","        label = normalize_label(b.get(\"raw_name\",\"damage\"))\n","        if label.isdigit(): label = \"damage\"\n","        text = (RU_LABEL if lang==\"ru\" else EN_LABEL).get(label, label)\n","        color = (66,165,245)\n","        draw.rectangle([x1,y1,x2,y2], width=3, outline=color)\n","        draw_label(draw, (x1,y1,x2,y2), f\"{text} {score:.2f}\")\n","        out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"label\":label, \"label_text\":text})\n","        crop = img.crop((max(0,x1-6), max(0,y1-6), min(img.width,x2+6), min(img.height,y2+6)))\n","        thumbs.append(crop)\n","    return out, vis, thumbs\n","\n","def health_score(cleanliness, dmg_counts, qflags):\n","    score = 100\n","    damage_total = sum(v for k,v in dmg_counts.items() if k in (\"scratch\",\"dent\",\"rust\"))\n","    dirt_total   = dmg_counts.get(\"dirt\", 0)\n","    score -= 12 * damage_total\n","    score -= 5  * dirt_total\n","    if cleanliness == \"dirty\": score -= 10\n","    score -= 5 * len(qflags)\n","    return int(max(0, min(100, score)))\n","\n","def badges(def_counts, qflags, lang=\"ru\"):\n","    chips = []\n","    for k,v in def_counts.items():\n","        if v<1: continue\n","        text = (RU_LABEL if lang==\"ru\" else EN_LABEL).get(k,k)\n","        chips.append(f\"<span class='badge {k}'>{text}: {v}</span>\")\n","    for _,txt in qflags:\n","        chips.append(f\"<span class='badge qf'>⚠︎ {txt}</span>\")\n","    return f\"<div class='badges'>{''.join(chips) if chips else '<span class=\\\"small\\\">Нет замечаний</span>'}</div>\"\n","\n","def meter(idx):\n","    idx = int(max(0,min(100, idx)))\n","    return f\"<div class='meter'><div style='width:{idx}%;'></div></div><div class='small'>Индекс состояния: <b>{idx}</b>/100</div>\"\n","\n","def do_analyze(img, usecrop, conf, lang):\n","    if img is None: return None\n","    img = img.convert(\"RGB\")\n","    cropped = crop_car(img) if usecrop else img\n","    qflags, qstats = quality_flags(cropped)\n","    cs = clip_cleanliness(cropped)\n","    boxes, vis, thumbs = detect_damage(cropped, conf_thr=float(conf), lang=lang)\n","    counts = {}\n","    for b in boxes: counts[b[\"label\"]] = counts.get(b[\"label\"],0)+1\n","    clean_label = \"dirty\" if cs[\"dirty\"]>cs[\"clean\"] else \"clean\"\n","    idx = health_score(clean_label, counts, qflags)\n","    status = (\"❌ Требуется осмотр\" if len(boxes)>0 else\n","              \"⚠️ Нужна мойка\" if clean_label==\"dirty\" else\n","              \"✅ Готово к размещению\")\n","    report = {\n","        \"ts\": int(time.time()),\n","        \"status\": status,\n","        \"cleanliness\": (\"грязная\" if clean_label==\"dirty\" else \"чистая\") if lang==\"ru\" else clean_label,\n","        \"damage\": (\"повреждён\" if len(boxes)>0 else \"неповреждён\") if lang==\"ru\" else (\"damaged\" if len(boxes)>0 else \"undamaged\"),\n","        \"damage_boxes\": boxes,\n","        \"quality_flags\": [t for _,t in qflags],\n","        \"quality_stats\": qstats,\n","        \"index_0_100\": idx\n","    }\n","    return vis, report, thumbs\n","\n","with gr.Blocks(css=CSS, title=\"Car State for inDrive\") as demo:\n","    gr.Markdown(\"<h1 class='title'>🚗 Определение состояния автомобиля</h1>\")\n","    lang = gr.Dropdown(choices=[\"ru\",\"en\"], value=\"ru\", label=\"Язык / Language\")\n","    with gr.Row():\n","        with gr.Column(scale=1):\n","            usecrop = gr.Checkbox(value=True, label=\"Кропать авто (YOLO)\")\n","            conf = gr.Slider(0.1,0.7,value=0.35,step=0.05,label=\"Порог уверенности повреждений\")\n","            with gr.Row():\n","                gr.Button(\"Агрессивный (0.25)\").click(lambda: gr.update(value=0.25), None, conf)\n","                gr.Button(\"Сбаланс. (0.35)\").click(lambda: gr.update(value=0.35), None, conf)\n","                gr.Button(\"Консервативный (0.45)\").click(lambda: gr.update(value=0.45), None, conf)\n","        with gr.Column(scale=4):\n","            in_img = gr.Image(type=\"pil\", label=\"Фото автомобиля\")\n","            run = gr.Button(\"Анализировать\", variant=\"primary\")\n","            out_img = gr.Image(label=\"Боксы\")\n","            info_html = gr.HTML()\n","            out_json = gr.Code(label=\"Отчёт (JSON)\", language=\"json\")\n","            meter_html = gr.HTML()\n","            status = gr.Textbox(label=\"Итоговый статус\", interactive=False)\n","\n","    def run_one(img, usecrop, conf, lang):\n","        res = do_analyze(img, usecrop, conf, lang)\n","        if not res: return None, \"\", \"\", \"\", \"\"\n","        vis, rep, thumbs = res\n","        counts={}\n","        for b in rep[\"damage_boxes\"]:\n","            counts[b[\"label\"]] = counts.get(b[\"label\"],0)+1\n","        chips = badges(counts, [(None,t) for t in rep[\"quality_flags\"]], lang=lang)\n","        return vis, chips, json.dumps(rep, ensure_ascii=False, indent=2), meter(rep[\"index_0_100\"]), rep[\"status\"]\n","\n","    run.click(run_one, inputs=[in_img, usecrop, conf, lang],\n","              outputs=[out_img, info_html, out_json, meter_html, status])\n","\n","if __name__ == \"__main__\":\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i1rzUWRoYbDb","executionInfo":{"status":"ok","timestamp":1757856056938,"user_tz":-300,"elapsed":56,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"3c69a495-ec4d-4d35-bf8a-b58f9e2ac1f9"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing /content/drive/MyDrive/indrive_hack/app.py\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/indrive_hack/app.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kmhd-wceYvM-","executionInfo":{"status":"ok","timestamp":1757856225229,"user_tz":-300,"elapsed":153801,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"cfbedda6-cd81-49ca-ab6e-cc0a51a96620"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1757856085.448616   17675 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1757856085.513682   17675 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1757856085.990724   17675 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757856085.990772   17675 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757856085.990777   17675 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757856085.990780   17675 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","config.json: 4.19kB [00:00, 19.2MB/s]\n","pytorch_model.bin: 100% 605M/605M [00:14<00:00, 42.0MB/s]\n","Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","Fetching 1 files:   0% 0/1 [00:00<?, ?it/s]\n","preprocessor_config.json: 100% 316/316 [00:00<00:00, 1.10MB/s]\n","Fetching 1 files: 100% 1/1 [00:00<00:00,  3.86it/s]\n","model.safetensors:   0% 0.00/605M [00:00<?, ?B/s]\n","tokenizer_config.json: 100% 592/592 [00:00<00:00, 5.59MB/s]\n","\n","vocab.json: 862kB [00:00, 42.9MB/s]\n","model.safetensors:   0% 1.70M/605M [00:00<03:50, 2.62MB/s]\n","merges.txt: 525kB [00:00, 80.9MB/s]\n","\n","tokenizer.json: 2.22MB [00:00, 66.3MB/s]\n","model.safetensors:  14% 84.4M/605M [00:01<00:10, 49.0MB/s]\n","special_tokens_map.json: 100% 389/389 [00:00<00:00, 2.48MB/s]\n","* Running on local URL:  http://0.0.0.0:7860\n","model.safetensors:  25% 151M/605M [00:08<00:28, 15.8MB/s] * Running on public URL: https://3ee3d0cc52f8c42614.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","model.safetensors: 100% 605M/605M [00:22<00:00, 27.3MB/s]\n","Keyboard interruption in main thread... closing server.\n","Killing tunnel 0.0.0.0:7860 <> https://3ee3d0cc52f8c42614.gradio.live\n"]}]},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/indrive_hack/theme.css\n",":root{\n","  --bg:#0a0f1a; --card:#0f1625; --stroke:#1e2a3c; --muted:#9fb0c7;\n","  --brand:#27c46b; --warn:#fbbf24; --danger:#ef4444; --accent:#60a5fa;\n","  --chip:#121b2b; --chip-stroke:#243244;\n","}\n",".gradio-container{max-width:1220px !important}\n","h1.title{margin:6px 0 10px}\n",".card{background:var(--card);border:1px solid var(--stroke);border-radius:12px;padding:14px}\n",".small{font-size:12px;color:var(--muted)}\n",".badges{display:flex;flex-wrap:wrap;gap:8px;margin:8px 0 2px}\n",".badge{padding:5px 10px;border-radius:999px;font-size:12px;border:1px solid var(--chip-stroke);background:var(--chip)}\n",".badge.scratch{color:#8ecbff;border-color:#1d3b63}\n",".badge.dent{color:#ffb3d2;border-color:#4a2644}\n",".badge.rust{color:#ffc792;border-color:#5a3b19}\n",".badge.dirt{color:#b7e4c7;border-color:#2a5a34}\n",".badge.qf{color:#ffb4b4;border-color:#3f2a2a}\n",".meter{height:14px;border-radius:8px;background:#122033;overflow:hidden;border:1px solid var(--stroke)}\n",".meter>div{height:100%;background:linear-gradient(90deg,#22c55e,#f59e0b,#ef4444)}\n",".pill{border:1px solid var(--stroke);padding:8px 10px;border-radius:10px;display:flex;align-items:center;gap:8px}\n",".kbd{border:1px solid var(--stroke);padding:1px 6px;border-radius:6px;background:#122033}\n",".row{display:flex;gap:12px;flex-wrap:wrap}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ggw5fGL7cPix","executionInfo":{"status":"ok","timestamp":1757857132520,"user_tz":-300,"elapsed":49,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"e489af4f-8438-41b2-b0ce-992fa604830d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/indrive_hack/theme.css\n"]}]},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/indrive_hack/app.py\n","import os, io, json, zipfile, time, base64\n","import gradio as gr\n","from PIL import Image, ImageDraw, ImageFilter\n","import numpy as np\n","import torch\n","from transformers import CLIPProcessor, CLIPModel\n","\n","WEI = \"/content/drive/MyDrive/indrive_hack/weights\"\n","CSS = \"/content/drive/MyDrive/indrive_hack/theme.css\"\n","\n","# ---------------------------\n","#  Models\n","# ---------------------------\n","crop_yolo = None\n","plate_yolo = None           # опционально: детектор номеров (если положишь weights/plate.pt)\n","damage_yolo = None\n","damage_yolo_v2 = None\n","damage_names = None\n","\n","try:\n","    from ultralytics import YOLO\n","    crop_yolo  = YOLO(\"yolov8n.pt\")\n","except Exception:\n","    crop_yolo = None\n","\n","try:\n","    from ultralytics import YOLO\n","    p_plate = os.path.join(WEI, \"plate.pt\")\n","    if os.path.exists(p_plate): plate_yolo = YOLO(p_plate)\n","except Exception:\n","    plate_yolo = None\n","\n","try:\n","    from ultralytics import YOLO\n","    p1 = os.path.join(WEI, \"damage_rust.pt\")\n","    p2 = os.path.join(WEI, \"damage_v2.pt\")\n","    if os.path.exists(p1):\n","        damage_yolo = YOLO(p1)\n","        try:\n","            damage_names = damage_yolo.model.names if hasattr(damage_yolo, \"model\") else damage_yolo.names\n","        except Exception:\n","            damage_names = None\n","    if os.path.exists(p2):\n","        damage_yolo_v2 = YOLO(p2)\n","except Exception:\n","    pass\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n","clip_proc  = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","# ---------------------------\n","#  Labels / UI\n","# ---------------------------\n","RU_LABEL = {\"scratch\":\"царапина\",\"dent\":\"вмятина\",\"rust\":\"ржавчина\",\"dirt\":\"грязь/пятно\",\"damage\":\"повреждение\"}\n","EN_LABEL = {\"scratch\":\"scratch\",\"dent\":\"dent\",\"rust\":\"rust\",\"dirt\":\"dirt\",\"damage\":\"damage\"}\n","\n","def _L(lang, ru, en): return ru if lang==\"ru\" else en\n","\n","# ---------------------------\n","#  Utils\n","# ---------------------------\n","def draw_label(draw, box, text):\n","    x1,y1,x2,y2 = box\n","    w = max(70, 12 + 8*len(text))\n","    draw.rectangle([x1, max(0,y1-18), x1+w, y1], fill=(0,0,0,160))\n","    draw.text((x1+6, max(0,y1-16)), text, fill=(255,255,255))\n","\n","def normalize_label(s):\n","    if not s: return \"damage\"\n","    s = str(s).lower()\n","    if \"scr\" in s: return \"scratch\"\n","    if \"dent\" in s or \"dunt\" in s: return \"dent\"\n","    if \"rust\" in s: return \"rust\"\n","    if \"dirt\" in s: return \"dirt\"\n","    return \"damage\"\n","\n","def crop_car(img: Image.Image) -> Image.Image:\n","    if crop_yolo is None: return img\n","    res = crop_yolo.predict(source=img, imgsz=640, conf=0.25, verbose=False)\n","    if not res: return img\n","    best_area, best_box = 0, None\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            try:\n","                if int(b.cls.item()) != 2:  # COCO: car\n","                    continue\n","                x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","                area = (x2-x1)*(y2-y1)\n","                if area > best_area:\n","                    best_area, best_box = area, (x1,y1,x2,y2)\n","            except:\n","                pass\n","    if best_box is None: return img\n","    x1,y1,x2,y2 = best_box\n","    x1=max(0,x1); y1=max(0,y1); x2=min(img.width,x2); y2=min(img.height,y2)\n","    return img.crop((x1,y1,x2,y2)) if x2>x1 and y2>y1 else img\n","\n","def blur_plates(img: Image.Image) -> Image.Image:\n","    if plate_yolo is None:\n","        return img\n","    res = plate_yolo.predict(source=img, imgsz=640, conf=0.25, verbose=False)\n","    out = img.copy()\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","            roi = out.crop((x1,y1,x2,y2)).filter(ImageFilter.GaussianBlur(radius=12))\n","            out.paste(roi, (x1,y1))\n","    return out\n","\n","@torch.no_grad()\n","def clip_cleanliness(img: Image.Image):\n","    texts = [\"a clean car photo\",\"a dirty, muddy car photo\"]\n","    inputs = clip_proc(text=texts, images=img, return_tensors=\"pt\", padding=True).to(device)\n","    probs = clip_model(**inputs).logits_per_image[0].softmax(dim=0).detach().cpu().numpy()\n","    return {\"clean\": float(probs[0]), \"dirty\": float(probs[1])}\n","\n","def quality_flags(img: Image.Image):\n","    arr = np.array(img.convert(\"L\"))\n","    bright = arr.mean(); contrast = arr.std()\n","    pad = np.pad(arr, 1, mode=\"edge\")\n","    lap = (pad[:-2,1:-1] + pad[2:,1:-1] + pad[1:-1,:-2] + pad[1:-1,2:] - 4*arr)\n","    sharp = float(lap.var())\n","    flags = []\n","    if bright < 70:  flags.append((\"low_light\",\"Низкая освещённость\"))\n","    if bright > 200: flags.append((\"overexp\",\"Пересвет\"))\n","    if contrast < 20:flags.append((\"low_contrast\",\"Низкий контраст\"))\n","    if sharp < 80:   flags.append((\"blurry\",\"Размыто\"))\n","    return flags, dict(bright=round(float(bright),1), contrast=round(float(contrast),1), sharp=round(sharp,1))\n","\n","def run_detector(detector, img: Image.Image, conf_thr=0.35, names_map=None):\n","    if detector is None: return []\n","    res = detector.predict(source=img, imgsz=640, conf=conf_thr, verbose=False)\n","    out = []\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","            score = float(b.conf.item())\n","            cls_id = int(b.cls.item()) if hasattr(b, \"cls\") else -1\n","            raw_name = names_map.get(cls_id, str(cls_id)) if isinstance(names_map, dict) else None\n","            out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"raw_name\": raw_name})\n","    return out\n","\n","def detect_damage(img: Image.Image, conf_thr=0.35, lang=\"ru\"):\n","    boxes_all = []\n","    boxes_all += run_detector(damage_yolo, img, conf_thr, names_map=damage_names)\n","    boxes_all += run_detector(damage_yolo_v2, img, conf_thr, names_map=None)\n","\n","    vis = img.copy()\n","    draw = ImageDraw.Draw(vis)\n","    out = []\n","    thumbs = []\n","    for b in boxes_all:\n","        x1,y1,x2,y2 = b[\"xyxy\"]; score = b[\"score\"]\n","        label = normalize_label(b.get(\"raw_name\",\"damage\"))\n","        if label.isdigit(): label = \"damage\"\n","        text = (RU_LABEL if lang==\"ru\" else EN_LABEL).get(label, label)\n","        draw.rectangle([x1,y1,x2,y2], width=3, outline=(96,165,255))\n","        draw_label(draw, (x1,y1,x2,y2), f\"{text} {score:.2f}\")\n","        out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"label\":label, \"label_text\":text})\n","        crop = img.crop((max(0,x1-6), max(0,y1-6), min(img.width,x2+6), min(img.height,y2+6)))\n","        thumbs.append(crop)\n","    return out, vis, thumbs\n","\n","def health_score(cleanliness, dmg_counts, qflags):\n","    score = 100\n","    damage_total = sum(v for k,v in dmg_counts.items() if k in (\"scratch\",\"dent\",\"rust\"))\n","    dirt_total   = dmg_counts.get(\"dirt\", 0)\n","    score -= 12 * damage_total\n","    score -= 5  * dirt_total\n","    if cleanliness == \"dirty\": score -= 10\n","    score -= 5 * len(qflags)\n","    return int(max(0, min(100, score)))\n","\n","def badges(def_counts, qflags, lang=\"ru\"):\n","    chips = []\n","    for k,v in def_counts.items():\n","        if v<1: continue\n","        text = (RU_LABEL if lang==\"ru\" else EN_LABEL).get(k,k)\n","        chips.append(f\"<span class='badge {k}'>{text}: {v}</span>\")\n","    for _,txt in qflags:\n","        chips.append(f\"<span class='badge qf'>⚠︎ {txt}</span>\")\n","    return f\"<div class='badges'>{''.join(chips) if chips else '<span class=\\\"small\\\">Нет замечаний</span>'}</div>\"\n","\n","def meter(idx):\n","    idx = int(max(0,min(100, idx)))\n","    return f\"<div class='meter'><div style='width:{idx}%;'></div></div><div class='small'>Индекс состояния: <b>{idx}</b>/100</div>\"\n","\n","def pack_report_zip(name, per_image_reports, summary_json, thumbs_map):\n","    path = f\"/content/{name}.zip\"\n","    with zipfile.ZipFile(path, \"w\", zipfile.ZIP_DEFLATED) as z:\n","        z.writestr(\"summary.json\", json.dumps(summary_json, ensure_ascii=False, indent=2))\n","        for i, rep in enumerate(per_image_reports, 1):\n","            z.writestr(f\"image_{i}/report.json\", json.dumps(rep, ensure_ascii=False, indent=2))\n","            for j, crop in enumerate(thumbs_map.get(i, []), 1):\n","                buf = io.BytesIO(); crop.save(buf, format=\"PNG\")\n","                z.writestr(f\"image_{i}/crop_{j}.png\", buf.getvalue())\n","    return path\n","\n","# ---------------------------\n","#  Core per-image inference\n","# ---------------------------\n","def analyze_single(img: Image.Image, usecrop: bool, conf: float, lang: str):\n","    if img is None: return None\n","    img = img.convert(\"RGB\")\n","    img = blur_plates(img)         # privacy first\n","    display = img.copy()\n","    processed = crop_car(img) if usecrop else img\n","\n","    qflags, qstats = quality_flags(processed)\n","    cs = clip_cleanliness(processed)\n","    boxes, vis, thumbs = detect_damage(processed, conf_thr=float(conf), lang=lang)\n","\n","    counts = {}\n","    for b in boxes: counts[b[\"label\"]] = counts.get(b[\"label\"],0)+1\n","    clean_label = \"dirty\" if cs[\"dirty\"]>cs[\"clean\"] else \"clean\"\n","    idx = health_score(clean_label, counts, qflags)\n","\n","    status = (\"❌ \" + _L(lang,\"Требуется осмотр\",\"Needs manual review\")) if len(boxes)>0 \\\n","        else (\"⚠️ \" + _L(lang,\"Нужна мойка\",\"Needs wash\")) if clean_label==\"dirty\" \\\n","        else (\"✅ \" + _L(lang,\"Готово к размещению\",\"OK to list\"))\n","\n","    per_image = {\n","        \"ts\": int(time.time()),\n","        \"status\": status,\n","        \"cleanliness\": (\"грязная\" if clean_label==\"dirty\" else \"чистая\") if lang==\"ru\" else clean_label,\n","        \"damage\": (\"повреждён\" if len(boxes)>0 else \"неповреждён\") if lang==\"ru\" else (\"damaged\" if len(boxes)>0 else \"undamaged\"),\n","        \"damage_boxes\": boxes,\n","        \"quality_flags\": [t for _,t in qflags],\n","        \"quality_stats\": qstats,\n","        \"index_0_100\": idx\n","    }\n","    return display, vis, thumbs, per_image, counts, clean_label, qflags, idx\n","\n","# ---------------------------\n","#  Gradio UI\n","# ---------------------------\n","with gr.Blocks(css=CSS, title=\"inDrive — Car Condition AI\") as demo:\n","    gr.Markdown(\"<h1 class='title'>🚗 AI-оценка состояния автомобиля</h1>\")\n","\n","    lang = gr.Dropdown(choices=[\"ru\",\"en\"], value=\"ru\", label=\"Язык / Language\")\n","\n","    with gr.Tabs():\n","        # ---- Tab 1: Upload\n","        with gr.TabItem(_L(\"ru\",\"1) Загрузка\",\"1) Upload\")):\n","            gr.Markdown(_L(lang,\n","                \"Загрузите до **3 фото** (разные ракурсы). Номера будут скрыты автоматически.\",\n","                \"Upload up to **3 photos** (different angles). Plates are blurred automatically.\")\n","            )\n","            gallery = gr.Gallery(label=_L(\"ru\",\"Фото\",\"Photos\"), columns=3, height=220, allow_preview=True)\n","            files = gr.Files(type='filepath', label=_L(\"ru\",\"Перетащите файлы сюда\",\"Drop files here\"))\n","\n","            def sync_files_to_gallery(fs):\n","                imgs = []\n","                for p in (fs or []):\n","                    try:\n","                        imgs.append(Image.open(p).convert(\"RGB\"))\n","                    except: pass\n","                return imgs[:3]\n","            files.change(sync_files_to_gallery, inputs=files, outputs=gallery)\n","\n","        # ---- Tab 2: Analyze\n","        with gr.TabItem(_L(\"ru\",\"2) Анализ\",\"2) Analyze\")):\n","            with gr.Row():\n","                with gr.Column(scale=1):\n","                    usecrop = gr.Checkbox(value=True, label=_L(\"ru\",\"Кропать авто (YOLO)\",\"Use YOLO crop\"))\n","                    conf = gr.Slider(0.1,0.7,value=0.35,step=0.05,label=_L(\"ru\",\"Порог уверенности повреждений\",\"Damage confidence\"))\n","                    with gr.Row():\n","                        gr.Button(\"0.25\").click(lambda: gr.update(value=0.25), None, conf)\n","                        gr.Button(\"0.35\").click(lambda: gr.update(value=0.35), None, conf)\n","                        gr.Button(\"0.45\").click(lambda: gr.update(value=0.45), None, conf)\n","                    analyze_btn = gr.Button(_L(\"ru\",\"Анализировать\",\"Analyze\"), variant=\"primary\")\n","                    help_html = gr.HTML(\"<div class='small'>\"\n","                                        f\"<span class='kbd'>Tip</span> {_L('ru','3 ракурса дают лучшую точность','3 angles improve accuracy')}</div>\")\n","\n","                with gr.Column(scale=3):\n","                    out_columns = gr.State(value=[])\n","                    out_imgs = gr.State(value=[])\n","                    agg_html = gr.HTML()\n","                    meter_html = gr.HTML()\n","                    status_txt = gr.Textbox(label=_L(\"ru\",\"Итоговый статус\",\"Final status\"), interactive=False)\n","\n","                    with gr.Accordion(_L(\"ru\",\"Детали по кадрам\",\"Per-image details\"), open=False):\n","                        per_cards = gr.HTML()\n","\n","            def run_batch(imgs, usecrop, conf, lang):\n","                imgs = imgs or []\n","                imgs = imgs[:3]\n","                per_reports = []\n","                thumbs_map = {}\n","                sum_counts = {}\n","                clean_votes = []\n","                all_flags = []\n","                indexes = []\n","                preview = []\n","\n","                for i, im in enumerate(imgs, 1):\n","                    disp, vis, thumbs, rep, counts, clean_label, qflags, idx = analyze_single(im, usecrop, conf, lang)\n","                    per_reports.append(rep)\n","                    thumbs_map[i] = thumbs\n","                    preview.append(vis)\n","\n","                    for k,v in counts.items():\n","                        sum_counts[k] = sum_counts.get(k,0)+v\n","                    clean_votes.append(clean_label)\n","                    all_flags.extend([t for _,t in qflags])\n","                    indexes.append(idx)\n","\n","                # агрегируем\n","                dirty_majority = clean_votes.count(\"dirty\") > clean_votes.count(\"clean\")\n","                agg_idx = int(np.mean(indexes)) if indexes else 0\n","                status = (\"❌ \" + _L(lang,\"Требуется осмотр\",\"Needs manual review\")) if sum(v for k,v in sum_counts.items() if k!=\"dirt\")>0 \\\n","                         else (\"⚠️ \" + _L(lang,\"Нужна мойка\",\"Needs wash\")) if dirty_majority \\\n","                         else (\"✅ \" + _L(lang,\"Готово к размещению\",\"OK to list\"))\n","\n","                chips = badges(sum_counts, [(None,t) for t in all_flags], lang=lang)\n","                html = f\"<div class='card'><div class='row'><div class='pill'>📸 {_L(lang,'Кадров','Frames')}: <b>{len(imgs)}</b></div>\" \\\n","                       f\"<div class='pill'>🛠 {_L(lang,'Дефекты (сумма)','Total defects')}: <b>{sum(sum_counts.values())}</b></div></div>{chips}</div>\"\n","\n","                # карточки по кадрам\n","                cards = []\n","                for i, rep in enumerate(per_reports, 1):\n","                    cards.append(f\"<div class='card'><div><b>#{i}</b> — {rep['status']}</div>\"\n","                                 f\"{meter(rep['index_0_100'])}\"\n","                                 f\"<div class='small'>{_L(lang,'Чистота','Cleanliness')}: {rep['cleanliness']} · \"\n","                                 f\"{_L(lang,'Флаги','Flags')}: {', '.join(rep['quality_flags']) if rep['quality_flags'] else _L(lang,'нет','none')}</div></div>\")\n","                cards_html = \"\".join(cards) if cards else f\"<div class='small'>{_L(lang,'Нет данных','No data')}</div>\"\n","\n","                summary = {\n","                    \"ts\": int(time.time()),\n","                    \"frames\": len(imgs),\n","                    \"status\": status,\n","                    \"defect_counts\": sum_counts,\n","                    \"quality_flags\": all_flags,\n","                    \"index_0_100\": agg_idx,\n","                    \"per_image\": per_reports\n","                }\n","\n","                return preview, summary, html, meter(agg_idx), status, cards_html\n","\n","            analyze_btn.click(\n","                fn=run_batch,\n","                inputs=[gallery, usecrop, conf, lang],\n","                outputs=[out_imgs, gr.State(), agg_html, meter_html, status_txt, per_cards],\n","            )\n","\n","        # ---- Tab 3: Report / Export\n","        with gr.TabItem(_L(\"ru\",\"3) Отчёт и выгрузка\",\"3) Report & Export\")):\n","            gr.Markdown(_L(\"ru\",\"Сгенерируйте архив отчёта (JSON + кропы).\",\"Generate report archive (JSON + crops).\"))\n","            name = gr.Textbox(value=\"indrive_report\", label=_L(\"ru\",\"Имя файла\",\"Filename\"))\n","            export_btn = gr.Button(_L(\"ru\",\"Скачать ZIP\",\"Download ZIP\"))\n","            out_json = gr.Code(label=\"Summary JSON\", language=\"json\")\n","            out_zip = gr.File(label=_L(\"ru\",\"ZIP отчёт\",\"ZIP report\"))\n","\n","            def export_zip(imgs, usecrop, conf, lang, name):\n","                if not imgs: return json.dumps({\"error\":\"no images\"}), None\n","                per_reports = []\n","                thumbs_map = {}\n","                for i, im in enumerate(imgs[:3], 1):\n","                    _, _, thumbs, rep, *_ = analyze_single(im, usecrop, conf, lang)\n","                    per_reports.append(rep); thumbs_map[i]=thumbs\n","                summary = {\n","                    \"ts\": int(time.time()),\n","                    \"frames\": len(per_reports),\n","                    \"per_image\": per_reports\n","                }\n","                path = pack_report_zip(name, per_reports, summary, thumbs_map)\n","                return json.dumps(summary, ensure_ascii=False, indent=2), path\n","\n","            export_btn.click(\n","                fn=export_zip,\n","                inputs=[gallery, usecrop, conf, lang, name],\n","                outputs=[out_json, out_zip]\n","            )\n","\n","if __name__ == \"__main__\":\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEfhzWG5cz9e","executionInfo":{"status":"ok","timestamp":1757857155064,"user_tz":-300,"elapsed":158,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"4262822f-702a-4a4c-eab8-aea6ea07db8e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/indrive_hack/app.py\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/indrive_hack/app.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ny7ImvJidExr","executionInfo":{"status":"ok","timestamp":1757857595553,"user_tz":-300,"elapsed":387958,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"0ce8d702-6722-4d94-df44-1c19d0ade4c3"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1757857219.667305   22429 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1757857219.681254   22429 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1757857219.732112   22429 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757857219.732184   22429 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757857219.732196   22429 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757857219.732205   22429 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","Fetching 1 files: 100% 1/1 [00:00<00:00, 14873.42it/s]\n","* Running on local URL:  http://0.0.0.0:7860\n","* Running on public URL: https://f3d5c498108d54ee0b.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\", line 667, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 349, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2274, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1781, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2476, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 915, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/indrive_hack/app.py\", line 301, in run_batch\n","    disp, vis, thumbs, rep, counts, clean_label, qflags, idx = analyze_single(im, usecrop, conf, lang)\n","                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/indrive_hack/app.py\", line 208, in analyze_single\n","    img = img.convert(\"RGB\")\n","          ^^^^^^^^^^^\n","AttributeError: 'tuple' object has no attribute 'convert'\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\", line 667, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 349, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2274, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1781, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2476, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 915, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/indrive_hack/app.py\", line 301, in run_batch\n","    disp, vis, thumbs, rep, counts, clean_label, qflags, idx = analyze_single(im, usecrop, conf, lang)\n","                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/indrive_hack/app.py\", line 208, in analyze_single\n","    img = img.convert(\"RGB\")\n","          ^^^^^^^^^^^\n","AttributeError: 'tuple' object has no attribute 'convert'\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\", line 667, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 349, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2274, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1781, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2476, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 915, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/indrive_hack/app.py\", line 363, in export_zip\n","    _, _, thumbs, rep, *_ = analyze_single(im, usecrop, conf, lang)\n","                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/indrive_hack/app.py\", line 208, in analyze_single\n","    img = img.convert(\"RGB\")\n","          ^^^^^^^^^^^\n","AttributeError: 'tuple' object has no attribute 'convert'\n","Keyboard interruption in main thread... closing server.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3158, in block_thread\n","    time.sleep(0.1)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/indrive_hack/app.py\", line 380, in <module>\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3055, in launch\n","    self.block_thread()\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3162, in block_thread\n","    self.server.close()\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/http_server.py\", line 69, in close\n","    self.thread.join(timeout=5)\n","  File \"/usr/lib/python3.12/threading.py\", line 1153, in join\n","    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n","  File \"/usr/lib/python3.12/threading.py\", line 1169, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","Killing tunnel 0.0.0.0:7860 <> https://f3d5c498108d54ee0b.gradio.live\n"]}]},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/indrive_hack/theme.css\n",":root{\n","  --bg:#0b1110;         /* глубокий тёмный */\n","  --panel:#111917;      /* панели */\n","  --muted:#18231f;\n","  --text:#e6f4ef;\n","  --sub:#a4cbbf;\n","  --green:#00e38e;      /* inDrive green */\n","  --green-2:#12b886;\n","  --amber:#f59e0b;\n","  --red:#ef4444;\n","  --line:#1d2c27;\n","}\n","* { font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, sans-serif; }\n",".gradio-container { max-width: 1200px; }\n","body, .gradio-container { background: var(--bg); color: var(--text); }\n",".md, .prose, .markdown-body { color: var(--text); }\n","div, input, textarea, button, .gradio-button { border-color: var(--line) !important; }\n","input, textarea, .wrap.svelte-1clx7zb, .form, .block, .container { background: var(--panel) !important; }\n","h1.title{ margin: 4px 0 12px; display:flex; gap:10px; align-items:center }\n","h1.title .badge{ background:var(--muted); color:var(--sub); padding:2px 8px; border-radius:999px; border:1px solid var(--line); font-size:12px }\n",".card { background: var(--panel); border:1px solid var(--line); border-radius:12px; padding:14px }\n",".kpi { display:grid; grid-template-columns:1fr 1fr; gap:12px }\n",".kpi .box{ background:var(--muted); border:1px solid var(--line); border-radius:10px; padding:10px }\n",".row { display:flex; gap:10px; align-items:center }\n",".badges { display:flex; flex-wrap:wrap; gap:6px; margin-top:6px }\n",".badge { padding:4px 8px; border-radius:999px; font-size:12px; border:1px solid var(--line) }\n",".badge.scratch{ background:#0b2447; color:#8ecbff }\n",".badge.dent   { background:#2a1630; color:#ffb3d2 }\n",".badge.rust   { background:#2a1f0e; color:#ffc792 }\n",".badge.dirt   { background:#122416; color:#b7e4c7 }\n",".badge.qf     { background:#261a1a; color:#ffb4b4 }\n",".meter { height:14px; border-radius:8px; background:#0f1715; overflow:hidden; border:1px solid var(--line) }\n",".meter > div { height:100%; background:linear-gradient(90deg,var(--green),var(--amber),var(--red)) }\n",".progress{ height:10px; border-radius:8px; background:#0f1715; border:1px solid var(--line); overflow:hidden; }\n",".progress > div{ height:100%; background:var(--green); }\n",".progress.red > div{ background:var(--red); }\n",".progress.amber > div{ background:var(--amber); }\n",".small { font-size:12px; color:var(--sub) }\n",".primary{ background:var(--green) !important; color:#002416 !important; border-color:transparent !important; }\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WvIIEQxyhN5_","executionInfo":{"status":"ok","timestamp":1757858297182,"user_tz":-300,"elapsed":173,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"78a02deb-dd2d-4b20-b693-6cbab18bde91"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/indrive_hack/theme.css\n"]}]},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/indrive_hack/app.py\n","import os, json, time\n","import gradio as gr\n","from PIL import Image, ImageDraw\n","import numpy as np\n","import torch\n","from transformers import CLIPProcessor, CLIPModel\n","\n","WEI = \"/content/drive/MyDrive/indrive_hack/weights\"\n","CSS = \"/content/drive/MyDrive/indrive_hack/theme.css\"\n","\n","# ── Модели ─────────────────────────────────────────────────────────────────────\n","crop_yolo = None\n","damage_yolo = None\n","damage_yolo_v2 = None\n","damage_names = None\n","\n","try:\n","    from ultralytics import YOLO\n","    crop_yolo = YOLO(\"yolov8n.pt\")      # COCO для кропа авто\n","except Exception:\n","    pass\n","\n","try:\n","    from ultralytics import YOLO\n","    p1 = os.path.join(WEI, \"damage_rust.pt\")  # базовая (rust/scratch/dent/car)\n","    p2 = os.path.join(WEI, \"damage_v2.pt\")    # дообученная (scratch/dent/dirt)\n","    if os.path.exists(p1):\n","        damage_yolo = YOLO(p1)\n","        try:\n","            damage_names = damage_yolo.model.names if hasattr(damage_yolo, \"model\") else damage_yolo.names\n","        except Exception:\n","            damage_names = None\n","    if os.path.exists(p2):\n","        damage_yolo_v2 = YOLO(p2)\n","except Exception:\n","    pass\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n","clip_proc  = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","RU = {\"clean\":\"чистый\",\"dirty\":\"грязный\",\"scratch\":\"царапина\",\"dent\":\"вмятина\",\"rust\":\"ржавчина\",\"dirt\":\"грязь/пятно\",\"damage\":\"повреждение\"}\n","EN = {\"clean\":\"clean\",\"dirty\":\"dirty\",\"scratch\":\"scratch\",\"dent\":\"dent\",\"rust\":\"rust\",\"dirt\":\"dirt\",\"damage\":\"damage\"}\n","\n","def t(lang, key):\n","    return (RU if lang==\"ru\" else EN).get(key, key)\n","\n","# ── Вспомогательные ───────────────────────────────────────────────────────────\n","def draw_label(draw, box, text):\n","    x1,y1,x2,y2 = box\n","    w = max(60, 10 + 8*len(text))\n","    draw.rectangle([x1, y1-18, x1+w, y1], fill=(0,0,0,170))\n","    draw.text((x1+6, y1-15), text, fill=(255,255,255))\n","\n","def normalize_label(s):\n","    if not s: return \"damage\"\n","    s = str(s).lower()\n","    if \"scr\" in s: return \"scratch\"\n","    if \"dent\" in s or \"dunt\" in s: return \"dent\"\n","    if \"rust\" in s: return \"rust\"\n","    if \"dirt\" in s: return \"dirt\"\n","    if \"car\" in s:  return \"car\"\n","    return s\n","\n","def crop_car(img: Image.Image) -> Image.Image:\n","    if crop_yolo is None: return img\n","    res = crop_yolo.predict(source=img, imgsz=640, conf=0.25, verbose=False)\n","    if not res: return img\n","    best_area, best_box = 0, None\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            try:\n","                if int(b.cls.item()) != 2:  # COCO \"car\"\n","                    continue\n","                x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","                area = (x2-x1)*(y2-y1)\n","                if area > best_area:\n","                    best_area, best_box = area, (x1,y1,x2,y2)\n","            except: pass\n","    if best_box is None: return img\n","    x1,y1,x2,y2 = best_box\n","    x1=max(0,x1); y1=max(0,y1); x2=min(img.width,x2); y2=min(img.height,y2)\n","    return img.crop((x1,y1,x2,y2)) if x2>x1 and y2>y1 else img\n","\n","@torch.no_grad()\n","def clip_cleanliness(img: Image.Image):\n","    texts = [\"a clean car photo\",\"a dirty, muddy car photo\"]\n","    inputs = clip_proc(text=texts, images=img, return_tensors=\"pt\", padding=True).to(device)\n","    probs = clip_model(**inputs).logits_per_image[0].softmax(dim=0).detach().cpu().numpy()\n","    return {\"clean\": float(probs[0]), \"dirty\": float(probs[1])}\n","\n","def quality_flags(img: Image.Image):\n","    arr = np.array(img.convert(\"L\"))\n","    bright = arr.mean(); contrast = arr.std()\n","    pad = np.pad(arr, 1, mode=\"edge\")\n","    lap = (pad[:-2,1:-1] + pad[2:,1:-1] + pad[1:-1,:-2] + pad[1:-1,2:] - 4*arr)\n","    sharp = float(lap.var())\n","    flags = []\n","    if bright < 70:  flags.append((\"low_light\",\"Низкая освещённость\"))\n","    if bright > 200: flags.append((\"overexp\",\"Пересвет\"))\n","    if contrast < 20:flags.append((\"low_contrast\",\"Низкий контраст\"))\n","    if sharp < 80:   flags.append((\"blurry\",\"Размыто\"))\n","    return flags, dict(bright=round(float(bright),1), contrast=round(float(contrast),1), sharp=round(sharp,1))\n","\n","def run_detector(detector, img: Image.Image, conf_thr=0.35, names_map=None):\n","    if detector is None: return []\n","    res = detector.predict(source=img, imgsz=640, conf=conf_thr, verbose=False)\n","    out = []\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","            score = float(b.conf.item())\n","            cls_id = int(b.cls.item()) if hasattr(b, \"cls\") else -1\n","            raw_name = names_map.get(cls_id, str(cls_id)) if isinstance(names_map, dict) else None\n","            out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"raw_name\": raw_name})\n","    return out\n","\n","def detect_damage(img: Image.Image, conf_thr=0.35, lang=\"ru\"):\n","    boxes_all = []\n","    boxes_all += run_detector(damage_yolo, img, conf_thr, names_map=damage_names)\n","    boxes_all += run_detector(damage_yolo_v2, img, conf_thr, names_map=None)\n","\n","    vis = img.copy()\n","    draw = ImageDraw.Draw(vis)\n","    out = []\n","    for b in boxes_all:\n","        x1,y1,x2,y2 = b[\"xyxy\"]; score = b[\"score\"]\n","        label = normalize_label(b.get(\"raw_name\",\"damage\"))\n","        if label.isdigit(): label = \"damage\"\n","        # цвет – один для аккуратного вида\n","        draw.rectangle([x1,y1,x2,y2], width=3, outline=(0,227,142))\n","        draw_label(draw, (x1,y1,x2,y2), f\"{t(lang,label)} {score:.2f}\")\n","        out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"label\":label, \"label_text\":t(lang,label)})\n","    return out, vis\n","\n","def health_score(cleanliness, dmg_counts, qflags):\n","    score = 100\n","    damage_total = sum(v for k,v in dmg_counts.items() if k in (\"scratch\",\"dent\",\"rust\"))\n","    dirt_total   = dmg_counts.get(\"dirt\", 0)\n","    score -= 12 * damage_total\n","    score -= 5  * dirt_total\n","    if cleanliness == \"dirty\": score -= 10\n","    score -= 5 * len(qflags)\n","    return int(max(0, min(100, score)))\n","\n","def percent_bar_html(label, p, danger=False):\n","    p = max(0, min(1.0, p))\n","    pct = int(round(p*100))\n","    cls = \"progress red\" if danger else \"progress\"\n","    return f\"<div class='small'>{label}: <b>{pct}%</b></div><div class='{cls}'><div style='width:{pct}%;'></div></div>\"\n","\n","def badges(def_counts, qflags, lang=\"ru\"):\n","    chips = []\n","    labels = RU if lang==\"ru\" else EN\n","    for k,v in def_counts.items():\n","        if v<1: continue\n","        chips.append(f\"<span class='badge {k}'>{labels.get(k,k)}: {v}</span>\")\n","    for _,txt in qflags:\n","        chips.append(f\"<span class='badge qf'>⚠︎ {txt}</span>\")\n","    return f\"<div class='badges'>{''.join(chips) if chips else '<span class=\\\"small\\\">Нет замечаний</span>'}</div>\"\n","\n","# ── Основная логика ────────────────────────────────────────────────────────────\n","def analyze(image: Image.Image, use_yolo_crop: bool, conf_thr: float, lang: str):\n","    if image is None:\n","        return None, gr.update(value=\"\"), gr.update(value=\"\"), gr.update(value=\"\"), gr.update(value=\"\")\n","\n","    img = image.convert(\"RGB\")\n","    cropped = crop_car(img) if use_yolo_crop else img\n","\n","    # качество и чистота\n","    qflags, qstats = quality_flags(cropped)\n","    cs = clip_cleanliness(cropped)\n","    clean_label = \"dirty\" if cs[\"dirty\"]>cs[\"clean\"] else \"clean\"\n","\n","    # детектор повреждений\n","    boxes, vis = detect_damage(cropped, conf_thr=float(conf_thr), lang=lang)\n","    counts={}\n","    avg_scores = {}\n","    for b in boxes:\n","        k = b[\"label\"]\n","        counts[k] = counts.get(k,0)+1\n","        avg_scores[k] = avg_scores.get(k,0.0) + b[\"score\"]\n","    for k in list(avg_scores.keys()):\n","        avg_scores[k] /= max(1, counts[k])\n","\n","    idx = health_score(clean_label, counts, qflags)\n","\n","    # проценты/индикаторы\n","    clean_block = (\n","        percent_bar_html(t(lang,\"clean\"), cs[\"clean\"], danger=False) +\n","        percent_bar_html(t(lang,\"dirty\"), cs[\"dirty\"], danger=True)\n","    )\n","    # «вероятность повреждён» из средней уверенности по боксам\n","    dmg_prob = max(0.0, min(1.0, sum(avg_scores.values())/max(1,len(avg_scores))))\n","    damage_block = (\n","        percent_bar_html((\"undamaged\" if lang==\"en\" else \"без повреждений\"), 1.0-dmg_prob, danger=False) +\n","        percent_bar_html((\"damaged\" if lang==\"en\" else \"повреждён\"), dmg_prob, danger=True)\n","    )\n","\n","    chips = badges(counts, [(None,t) for _,t in qflags], lang=lang)\n","    meter = f\"<div class='meter'><div style='width:{idx}%;'></div></div><div class='small'>{('Vehicle health index' if lang=='en' else 'Индекс состояния')}: <b>{idx}</b>/100</div>\"\n","\n","    # итоговый статус\n","    status = (\"❌ Требуется осмотр\" if len(boxes)>0 else\n","              \"⚠️ Нужна мойка\" if clean_label==\"dirty\" else\n","              \"✅ Готово к размещению\")\n","    if lang==\"en\":\n","        status = (\"❌ Needs inspection\" if len(boxes)>0 else\n","                  \"⚠️ Car wash recommended\" if clean_label==\"dirty\" else\n","                  \"✅ OK to list\")\n","\n","    report = {\n","        \"ts\": int(time.time()),\n","        \"status\": status,\n","        \"cleanliness\": t(lang, clean_label),\n","        \"damage_boxes\": boxes,\n","        \"quality_flags\": [txt for _,txt in qflags],\n","        \"quality_stats\": qstats,\n","        \"index_0_100\": idx\n","    }\n","\n","    # HTML для KPI\n","    kpi_html = f\"\"\"\n","    <div class='kpi'>\n","      <div class='box'>\n","        <div class='small'>{'Cleanliness' if lang=='en' else 'Чистота'}</div>\n","        {clean_block}\n","      </div>\n","      <div class='box'>\n","        <div class='small'>{'Damage' if lang=='en' else 'Повреждения'}</div>\n","        {damage_block}\n","      </div>\n","    </div>\n","    <div style='height:8px'></div>\n","    {chips}\n","    <div style='height:8px'></div>\n","    {meter}\n","    <div style='height:8px'></div>\n","    <div class='small'><b>{'Final status' if lang=='en' else 'Итоговый статус'}:</b> {status}</div>\n","    \"\"\"\n","\n","    return vis, kpi_html, json.dumps(report, ensure_ascii=False, indent=2), status, idx\n","\n","# ── UI ─────────────────────────────────────────────────────────────────────────\n","with gr.Blocks(css=CSS, title=\"Оценка состояния автомобиля для inDrive\") as demo:\n","    gr.Markdown(\"<h1 class='title'>🚗 Оценка состояния автомобиля для inDrive <span class='badge'>beta</span></h1>\")\n","    lang = gr.Dropdown(choices=[\"ru\",\"en\"], value=\"ru\", label=\"Язык / Language\")\n","\n","    with gr.Row():\n","        with gr.Column(scale=1):\n","            in_img  = gr.Image(type=\"pil\", label=\"Фото автомобиля (1 изображение)\")\n","            usecrop = gr.Checkbox(value=True, label=\"Кропать авто (YOLO)\")\n","            conf    = gr.Slider(0.1, 0.7, value=0.35, step=0.05, label=\"Порог уверенности повреждений\")\n","            with gr.Row():\n","                gr.Button(\"0.25\").click(lambda: gr.update(value=0.25), None, conf)\n","                gr.Button(\"0.35\").click(lambda: gr.update(value=0.35), None, conf)\n","                gr.Button(\"0.45\").click(lambda: gr.update(value=0.45), None, conf)\n","            run     = gr.Button(\"Анализировать\", elem_classes=[\"primary\"])\n","            gr.Markdown(\"<div class='small'>Подсказка: фронт/зад/¾ — дают лучшую точность.</div>\")\n","        with gr.Column(scale=2):\n","            out_img  = gr.Image(label=\"Разметка (боксы)\")\n","            kpi_html = gr.HTML(label=\"Индикаторы\")\n","            out_json = gr.Code(label=\"Отчёт (JSON)\", language=\"json\")\n","            status   = gr.Textbox(label=\"Итоговый статус\", interactive=False)\n","            idx_box  = gr.Number(label=\"Индекс состояния (0–100)\", interactive=False)\n","\n","    run.click(\n","        analyze,\n","        inputs=[in_img, usecrop, conf, lang],\n","        outputs=[out_img, kpi_html, out_json, status, idx_box]\n","    )\n","\n","if __name__ == \"__main__\":\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8dTN_elUhQF3","executionInfo":{"status":"ok","timestamp":1757858317859,"user_tz":-300,"elapsed":162,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"4ebb6791-bdee-4999-b27d-077b76370ef4"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/indrive_hack/app.py\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/indrive_hack/app.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RAmzUcsDhXDN","executionInfo":{"status":"ok","timestamp":1757858605788,"user_tz":-300,"elapsed":274940,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"cfc98fa8-a472-4390-e549-a6a10fbaed35"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1757858339.987910   27083 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1757858339.995279   27083 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1757858340.013343   27083 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757858340.013385   27083 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757858340.013390   27083 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757858340.013396   27083 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","Fetching 1 files: 100% 1/1 [00:00<00:00, 15827.56it/s]\n","* Running on local URL:  http://0.0.0.0:7860\n","* Running on public URL: https://5b006c6f3178530188.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","Keyboard interruption in main thread... closing server.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3158, in block_thread\n","    time.sleep(0.1)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/indrive_hack/app.py\", line 276, in <module>\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3055, in launch\n","    self.block_thread()\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3162, in block_thread\n","    self.server.close()\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/http_server.py\", line 69, in close\n","    self.thread.join(timeout=5)\n","  File \"/usr/lib/python3.12/threading.py\", line 1153, in join\n","    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n","  File \"/usr/lib/python3.12/threading.py\", line 1169, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","Killing tunnel 0.0.0.0:7860 <> https://5b006c6f3178530188.gradio.live\n"]}]},{"cell_type":"code","source":["/* ===== inDrive dark/green ===== */\n",":root{\n","  --bg:#0b0f12; --panel:#121820; --muted:#93a3b3; --line:#1d2b36;\n","  --accent:#22c55e; /* inDrive green */\n","  --accent-2:#16a34a; --danger:#ef4444; --warn:#f59e0b;\n","}\n",".gradio-container{max-width:1200px}\n","h1.title{margin:8px 0 10px}\n","footer.foot{margin-top:12px;color:var(--muted);text-align:center}\n","\n","/* компактный селектор языка — вправо, фикс. ширина */\n",".lang-row .wrap{display:flex;justify-content:flex-end}\n",".lang-row .wrap > div{width:220px}\n","\n","/* карточки/панели */\n",".card{background:var(--panel);border:1px solid var(--line);border-radius:12px;padding:12px}\n","\n","/* шкалы */\n",".mbar{margin:8px 0 12px}\n",".mbar .label{display:flex;justify-content:space-between;font-size:13px;color:var(--muted)}\n",".mbar .track{height:12px;background:#0f141a;border:1px solid var(--line);border-radius:8px;overflow:hidden}\n",".mbar .fill{height:100%;background:linear-gradient(90deg,var(--accent),var(--accent-2))}\n",".mbar.warn .fill{background:linear-gradient(90deg,var(--warn),#facc15)}\n",".mbar.danger .fill{background:linear-gradient(90deg,var(--danger),#f43f5e)}\n","\n","/* бэйджи */\n",".badges{display:flex;flex-wrap:wrap;gap:6px;margin-top:6px}\n",".badge{padding:4px 8px;border-radius:999px;font-size:12px;border:1px solid var(--line);background:#0f141a}\n",".badge.qf{border-color:#3f2a2a;color:#ffb4b4;background:#261a1a}\n","\n","/* маленькое превью бокс-изображения */\n",".box-preview img{max-height:330px;border:1px solid var(--line);border-radius:10px}\n",".small{font-size:12px;color:var(--muted)}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"lUKVH6rckTFL","executionInfo":{"status":"error","timestamp":1757859104865,"user_tz":-300,"elapsed":82,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"bfd84c75-686b-4fb5-ebca-0d1d43295efa"},"execution_count":21,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid decimal literal (ipython-input-4139269113.py, line 7)","traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4139269113.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    .gradio-container{max-width:1200px}\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"]}]},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/indrive_hack/app.py\n","import os, json, time\n","import gradio as gr\n","from PIL import Image, ImageDraw\n","import numpy as np\n","import torch\n","from transformers import CLIPProcessor, CLIPModel\n","\n","WEI = \"/content/drive/MyDrive/indrive_hack/weights\"\n","CSS = \"/content/drive/MyDrive/indrive_hack/theme.css\"\n","\n","# --------- Models ----------\n","crop_yolo = None\n","try:\n","    from ultralytics import YOLO\n","    crop_yolo = YOLO(\"yolov8n.pt\")\n","except Exception:\n","    pass\n","\n","damage_yolo = None\n","damage_yolo_v2 = None\n","damage_names = None\n","try:\n","    from ultralytics import YOLO\n","    p1 = os.path.join(WEI, \"damage_rust.pt\")\n","    p2 = os.path.join(WEI, \"damage_v2.pt\")\n","    if os.path.exists(p1):\n","        damage_yolo = YOLO(p1)\n","        try:\n","            damage_names = damage_yolo.model.names if hasattr(damage_yolo, \"model\") else damage_yolo.names\n","        except Exception:\n","            damage_names = None\n","    if os.path.exists(p2):\n","        damage_yolo_v2 = YOLO(p2)\n","except Exception:\n","    pass\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n","clip_proc  = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","RU_LABEL = {\"scratch\":\"царапина\",\"dent\":\"вмятина\",\"rust\":\"ржавчина\",\"dirt\":\"грязь/пятно\",\"damage\":\"повреждение\"}\n","EN_LABEL = {\"scratch\":\"scratch\",\"dent\":\"dent\",\"rust\":\"rust\",\"dirt\":\"dirt\",\"damage\":\"damage\"}\n","\n","# ---------- Utils ----------\n","def draw_tag(draw, box, text):\n","    x1,y1,x2,y2 = box\n","    pad = 3\n","    w = max(80, len(text)*7)\n","    draw.rectangle([x1, y1-18, x1+w, y1], fill=(0,0,0,160))\n","    draw.text((x1+pad, y1-15), text, fill=(255,255,255))\n","\n","def normalize_label(s):\n","    if not s: return \"damage\"\n","    s = str(s).lower()\n","    if \"scr\" in s: return \"scratch\"\n","    if \"dent\" in s or \"dunt\" in s: return \"dent\"\n","    if \"rust\" in s: return \"rust\"\n","    if \"dirt\" in s: return \"dirt\"\n","    return \"damage\"\n","\n","def crop_car(img: Image.Image) -> Image.Image:\n","    if crop_yolo is None: return img\n","    res = crop_yolo.predict(source=img, imgsz=640, conf=0.25, verbose=False)\n","    best_box = None; best_area = 0\n","    for r in res or []:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            try:\n","                if int(b.cls.item()) != 2:  # COCO 'car'\n","                    continue\n","                x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","                area = (x2-x1)*(y2-y1)\n","                if area>best_area: best_area, best_box = area, (x1,y1,x2,y2)\n","            except: pass\n","    if not best_box: return img\n","    x1,y1,x2,y2 = best_box\n","    x1=max(0,x1); y1=max(0,y1); x2=min(img.width,x2); y2=min(img.height,y2)\n","    return img.crop((x1,y1,x2,y2)) if x2>x1 and y2>y1 else img\n","\n","@torch.no_grad()\n","def clip_cleanliness(img: Image.Image):\n","    texts = [\"a clean car photo\", \"a dirty, muddy car photo\"]\n","    inputs = clip_proc(text=texts, images=img, return_tensors=\"pt\", padding=True).to(device)\n","    probs = clip_model(**inputs).logits_per_image[0].softmax(dim=0).detach().cpu().numpy()\n","    return {\"clean\": float(probs[0]), \"dirty\": float(probs[1])}\n","\n","def quality_flags(img: Image.Image):\n","    arr = np.array(img.convert(\"L\"))\n","    bright = arr.mean(); contrast = arr.std()\n","    pad = np.pad(arr, 1, mode=\"edge\")\n","    lap = (pad[:-2,1:-1] + pad[2:,1:-1] + pad[1:-1,:-2] + pad[1:-1,2:] - 4*arr)\n","    sharp = float(lap.var())\n","    flags = []\n","    if bright < 70:  flags.append((\"low_light\",\"Низкая освещённость\"))\n","    if bright > 200: flags.append((\"overexp\",\"Пересвет\"))\n","    if contrast < 20:flags.append((\"low_contrast\",\"Низкий контраст\"))\n","    if sharp < 80:   flags.append((\"blurry\",\"Размыто\"))\n","    return flags, dict(bright=round(float(bright),1), contrast=round(float(contrast),1), sharp=round(sharp,1))\n","\n","def run_detector(detector, img, conf_thr=0.35, names_map=None):\n","    if detector is None: return []\n","    res = detector.predict(source=img, imgsz=640, conf=conf_thr, verbose=False)\n","    out=[]\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","            score = float(b.conf.item())\n","            cls_id = int(b.cls.item()) if hasattr(b, \"cls\") else -1\n","            raw_name = names_map.get(cls_id, str(cls_id)) if isinstance(names_map, dict) else None\n","            out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"raw_name\":raw_name})\n","    return out\n","\n","def detect_damage(img: Image.Image, conf_thr=0.35, lang=\"ru\"):\n","    boxes_all = []\n","    boxes_all += run_detector(damage_yolo, img, conf_thr, names_map=damage_names)\n","    boxes_all += run_detector(damage_yolo_v2, img, conf_thr, names_map=None)\n","\n","    vis = img.copy()\n","    draw = ImageDraw.Draw(vis)\n","    out=[]; thumbs=[]\n","    L = RU_LABEL if lang==\"ru\" else EN_LABEL\n","    for b in boxes_all:\n","        x1,y1,x2,y2 = b[\"xyxy\"]; score=b[\"score\"]\n","        label = normalize_label(b.get(\"raw_name\",\"damage\"))\n","        tag = L.get(label, label)\n","        draw.rectangle([x1,y1,x2,y2], outline=(34,197,94), width=3)\n","        draw_tag(draw,(x1,y1,x2,y2), f\"{tag} {score:.2f}\")\n","        out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"label\":label, \"label_text\":tag})\n","        thumbs.append(img.crop((max(0,x1-6), max(0,y1-6), min(img.width,x2+6), min(img.height,y2+6))))\n","    return out, vis, thumbs\n","\n","def damage_probs(boxes):\n","    \"\"\"Собираем 'вероятности' как у конкурента (примерная агрегация).\"\"\"\n","    if not boxes:\n","        return {\"undamaged\":1.0, \"minor\":0.0, \"severe\":0.0}\n","    scores = [min(1.0, max(0.0, b[\"score\"])) for b in boxes]\n","    p_damage = 1.0\n","    for s in scores: p_damage *= (1.0 - s)\n","    p_damage = 1.0 - p_damage  # вероятность наличия любого дефекта\n","    max_s = max(scores)\n","    p_severe = max(0.0, (max_s - 0.60) / 0.40)  # >0.6 считаем сильным\n","    p_severe = min(p_severe, p_damage)\n","    p_minor  = max(0.0, p_damage - p_severe)\n","    p_undmg  = max(0.0, 1.0 - p_damage)\n","    # нормировка\n","    s = p_undmg + p_minor + p_severe\n","    if s>0: p_undmg, p_minor, p_severe = (p_undmg/s, p_minor/s, p_severe/s)\n","    return {\"undamaged\":p_undmg, \"minor\":p_minor, \"severe\":p_severe}\n","\n","def health_score(cleanliness, dmg_counts, qflags):\n","    score = 100\n","    damage_total = sum(v for k,v in dmg_counts.items() if k in (\"scratch\",\"dent\",\"rust\",\"damage\"))\n","    dirt_total   = dmg_counts.get(\"dirt\", 0)\n","    score -= 12 * damage_total\n","    score -= 5  * dirt_total\n","    if cleanliness == \"dirty\": score -= 10\n","    score -= 5 * len(qflags)\n","    return int(max(0, min(100, score)))\n","\n","def bar(label_left, label_right, value, kind=\"ok\"):\n","    v = int(round(100*max(0,min(1.0,value))))\n","    cls = \"mbar\" + (\"\" if kind==\"ok\" else f\" {kind}\")\n","    return f\"\"\"\n","      <div class=\"{cls}\">\n","        <div class=\"label\"><span>{label_left}</span><span>{v}%</span></div>\n","        <div class=\"track\"><div class=\"fill\" style=\"width:{v}%;\"></div></div>\n","      </div>\"\"\"\n","\n","def bars_html(lang, clean_probs, dmg_probs):\n","    if lang==\"ru\":\n","        s1 = bar(\"Чистый\", \"Clean\", clean_probs[\"clean\"], \"ok\")\n","        s2 = bar(\"Грязный\", \"Dirty\", clean_probs[\"dirty\"], \"warn\")\n","        d1 = bar(\"Неповреждённый\", \"Undamaged\", dmg_probs[\"undamaged\"], \"ok\")\n","        d2 = bar(\"Незначительные\", \"Minor\", dmg_probs[\"minor\"], \"warn\")\n","        d3 = bar(\"Серьёзные\", \"Severe\", dmg_probs[\"severe\"], \"danger\")\n","        title1, title2 = \"Чистота\", \"Повреждения\"\n","    else:\n","        s1 = bar(\"Clean\", \"Clean\", clean_probs[\"clean\"], \"ok\")\n","        s2 = bar(\"Dirty\", \"Dirty\", clean_probs[\"dirty\"], \"warn\")\n","        d1 = bar(\"Undamaged\", \"Undamaged\", dmg_probs[\"undamaged\"], \"ok\")\n","        d2 = bar(\"Minor\", \"Minor\", dmg_probs[\"minor\"], \"warn\")\n","        d3 = bar(\"Severe\", \"Severe\", dmg_probs[\"severe\"], \"danger\")\n","        title1, title2 = \"Cleanliness\", \"Damage\"\n","    return f\"\"\"\n","      <div class=\"card\">\n","        <div class=\"small\">📊 {title1}</div>{s1}{s2}\n","      </div>\n","      <div class=\"card\">\n","        <div class=\"small\">🔧 {title2}</div>{d1}{d2}{d3}\n","      </div>\n","    \"\"\"\n","\n","def badges(def_counts, qflags, lang=\"ru\"):\n","    chips=[]\n","    L = RU_LABEL if lang==\"ru\" else EN_LABEL\n","    for k,v in def_counts.items():\n","        if v<1: continue\n","        chips.append(f\"<span class='badge'>{L.get(k,k)}: {v}</span>\")\n","    for _,txt in qflags:\n","        chips.append(f\"<span class='badge qf'>⚠︎ {txt}</span>\")\n","    return \"<div class='badges'>\" + (\"\".join(chips) if chips else \"<span class='small'>Нет замечаний</span>\") + \"</div>\"\n","\n","def do_analyze(img, usecrop, conf, lang):\n","    if img is None: return None\n","    img = img.convert(\"RGB\")\n","    cropped = crop_car(img) if usecrop else img\n","\n","    qflags, qstats = quality_flags(cropped)\n","    clean = clip_cleanliness(cropped)\n","    boxes, vis, thumbs = detect_damage(cropped, conf_thr=float(conf), lang=lang)\n","\n","    counts={}\n","    for b in boxes: counts[b[\"label\"]] = counts.get(b[\"label\"],0)+1\n","    clean_label = \"dirty\" if clean[\"dirty\"]>clean[\"clean\"] else \"clean\"\n","    idx = health_score(clean_label, counts, qflags)\n","\n","    pd = damage_probs(boxes)\n","    chips = badges(counts, [(None,t) for _,t in qflags], lang=lang)\n","    bars = bars_html(lang, clean, pd)\n","\n","    status = (\"❌ Требуется осмотр\" if boxes else\n","              \"⚠️ Нужна мойка\" if clean_label==\"dirty\" else\n","              \"✅ Готово к размещению\")\n","\n","    report = {\n","        \"ts\": int(time.time()),\n","        \"status\": status,\n","        \"cleanliness_probs\": clean,\n","        \"damage_probs\": pd,\n","        \"damage_boxes\": boxes,\n","        \"quality_flags\": [t for _,t in qflags],\n","        \"quality_stats\": qstats,\n","        \"index_0_100\": idx\n","    }\n","    return vis, bars, chips, json.dumps(report, ensure_ascii=False, indent=2), status\n","\n","# ---------- UI ----------\n","with gr.Blocks(css=CSS, title=\"Оценка состояния автомобиля для inDrive\") as demo:\n","    gr.Markdown(\"<h1 class='title'>🚗 Оценка состояния автомобиля для inDrive</h1>\")\n","\n","    with gr.Row(elem_classes=[\"lang-row\"]):\n","        lang = gr.Dropdown(choices=[\"ru\",\"en\"], value=\"ru\", label=\"Язык / Language\")\n","\n","    with gr.Row():\n","        with gr.Column(scale=5):\n","            in_img = gr.Image(type=\"pil\", label=\"Фото автомобиля\")\n","            with gr.Group():\n","                usecrop = gr.Checkbox(value=True, label=\"Кропать авто (YOLO)\")\n","                conf = gr.Slider(0.1, 0.7, value=0.35, step=0.05, label=\"Порог уверенности повреждений\")\n","                with gr.Row():\n","                    gr.Button(\"0.25\").click(lambda: gr.update(value=0.25), None, conf)\n","                    gr.Button(\"0.35\").click(lambda: gr.update(value=0.35), None, conf)\n","                    gr.Button(\"0.45\").click(lambda: gr.update(value=0.45), None, conf)\n","            run = gr.Button(\"Анализировать\", variant=\"primary\")\n","        with gr.Column(scale=7):\n","            # шкалы + бейджи\n","            bars_html_out = gr.HTML()\n","            chips_out = gr.HTML()\n","            # сворачиваемая разметка, уменьшенное изображение\n","            with gr.Accordion(\"Разметка (боксы)\", open=False):\n","                out_img = gr.Image(label=None, elem_classes=[\"box-preview\"], height=330)\n","            # сводка\n","            out_json = gr.Code(label=\"Отчёт (JSON)\", language=\"json\")\n","            status = gr.Textbox(label=\"Итоговый статус\", interactive=False)\n","\n","    def run_one(img, usecrop, conf, lang):\n","        res = do_analyze(img, usecrop, conf, lang)\n","        if not res: return \"\", \"\", \"\", \"\", \"\"\n","        return res  # vis, bars, chips, json, status\n","\n","    run.click(run_one, inputs=[in_img, usecrop, conf, lang],\n","              outputs=[out_img, bars_html_out, chips_out, out_json, status])\n","\n","    gr.Markdown(\"<div class='foot'>Сделано с любовью от команды <b>DOGS</b> для inDrive</div>\")\n","\n","if __name__ == \"__main__\":\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6r5ffCyxkg4N","executionInfo":{"status":"ok","timestamp":1757859165166,"user_tz":-300,"elapsed":86,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"c569b734-4f48-4c0d-a981-6384d5b284db"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/indrive_hack/app.py\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/indrive_hack/app.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPO_UlfkkmCo","executionInfo":{"status":"ok","timestamp":1757859966349,"user_tz":-300,"elapsed":787146,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"1143f9fa-fe9b-44c0-c65e-22bdc80f7f4e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1757859188.199362   30614 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1757859188.206880   30614 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1757859188.225167   30614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757859188.225208   30614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757859188.225212   30614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757859188.225216   30614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","Fetching 1 files: 100% 1/1 [00:00<00:00, 15947.92it/s]\n","* Running on local URL:  http://0.0.0.0:7860\n","* Running on public URL: https://dc5700da1899ad5893.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3158, in block_thread\n","    time.sleep(0.1)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/indrive_hack/app.py\", line 278, in <module>\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3055, in launch\n","    self.block_thread()\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3160, in block_thread\n","    print(\"Keyboard interruption in main thread... closing server.\")\n","KeyboardInterrupt\n","Killing tunnel 0.0.0.0:7860 <> https://dc5700da1899ad5893.gradio.live\n"]}]},{"cell_type":"code","source":["# %%writefile /content/drive/MyDrive/indrive_hack/app.py\n","import os, time, json\n","from typing import Dict, List, Tuple\n","\n","import gradio as gr\n","from PIL import Image, ImageDraw\n","import numpy as np\n","import torch\n","from transformers import CLIPProcessor, CLIPModel\n","\n","# --------------------------------------------------\n","# Константы и пути\n","# --------------------------------------------------\n","WEI = \"/content/drive/MyDrive/indrive_hack/weights\"\n","THEME_CSS = \"\"\"\n",".gradio-container {max-width: 1180px}\n","h1.title {margin: 8px 0 14px}\n",".card {background:#0a1116;border:1px solid #1b2b33;border-radius:12px;padding:14px}\n",".kv {line-height:1.35}\n",".kv b{color:#e6f4ee}\n",".kv .sec{margin-top:8px;color:#96b2a7}\n",".kv .ok{color:#22c55e}\n",".kv .warn{color:#f59e0b}\n",".kv .bad{color:#ef4444}\n",".sep{height:1px;background:#18313a;margin:10px 0;border-radius:999px}\n",".footer{opacity:.7;margin-top:14px;font-size:12px}\n",".lang-row .wrap {display:flex;gap:8px;align-items:center}\n",".lang-row .wrap > div {flex:0 0 180px}\n",".box-preview img{max-height:330px;object-fit:contain}\n",".primary-btn {background:#16a34a !important;border-color:#16a34a !important}\n","\"\"\"\n","\n","# --------------------------------------------------\n","# Загрузка моделей (кэш, без повторов)\n","# --------------------------------------------------\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","def _load_clip():\n","    mdl = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n","    proc = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","    return mdl, proc\n","\n","def _load_yolos():\n","    crop, d1, d2, names = None, None, None, None\n","    try:\n","        from ultralytics import YOLO\n","        crop = YOLO(\"yolov8n.pt\")  # для кропа авто\n","    except Exception:\n","        pass\n","    try:\n","        from ultralytics import YOLO\n","        p1 = os.path.join(WEI, \"damage_rust.pt\")   # «первая» (rust/scratch/dent/dirt)\n","        p2 = os.path.join(WEI, \"damage_v2.pt\")     # «вторая» на другом датасете\n","        if os.path.exists(p1):\n","            d1 = YOLO(p1)\n","            try:\n","                names = d1.model.names if hasattr(d1, \"model\") else d1.names\n","            except Exception:\n","                names = None\n","        if os.path.exists(p2):\n","            d2 = YOLO(p2)\n","    except Exception:\n","        pass\n","    return crop, d1, d2, names\n","\n","CLIP_MODEL, CLIP_PROC = _load_clip()\n","CROP_YOLO, DMG1, DMG2, DMG1_NAMES = _load_yolos()\n","\n","# --------------------------------------------------\n","# Справочники/подписи\n","# --------------------------------------------------\n","RU_LABEL = {\"scratch\":\"царапина\",\"dent\":\"вмятина\",\"rust\":\"ржавчина\",\"dirt\":\"грязь/пятно\",\"damage\":\"повреждение\"}\n","EN_LABEL = {\"scratch\":\"scratch\",\"dent\":\"dent\",\"rust\":\"rust\",\"dirt\":\"dirt\",\"damage\":\"damage\"}\n","\n","def _norm_label(s: str) -> str:\n","    if not s: return \"damage\"\n","    s = str(s).lower()\n","    if \"scr\" in s: return \"scratch\"\n","    if \"dent\" in s or \"dunt\" in s: return \"dent\"\n","    if \"rust\" in s: return \"rust\"\n","    if \"dirt\" in s: return \"dirt\"\n","    return \"damage\"\n","\n","# --------------------------------------------------\n","# Вспомогательные функции\n","# --------------------------------------------------\n","def crop_car(img: Image.Image) -> Image.Image:\n","    if CROP_YOLO is None: return img\n","    res = CROP_YOLO.predict(source=img, imgsz=640, conf=0.25, verbose=False)\n","    if not res: return img\n","    best_area, best_box = 0, None\n","    for r in res:\n","        if getattr(r, \"boxes\", None) is None: continue\n","        for b in r.boxes:\n","            try:\n","                if int(b.cls.item()) != 2:  # COCO: car\n","                    continue\n","                x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","                area = max(0,(x2-x1))*max(0,(y2-y1))\n","                if area > best_area:\n","                    best_area, best_box = area, (x1,y1,x2,y2)\n","            except Exception:\n","                pass\n","    if best_box is None: return img\n","    x1,y1,x2,y2 = best_box\n","    x1=max(0,x1); y1=max(0,y1); x2=min(img.width,x2); y2=min(img.height,y2)\n","    return img.crop((x1,y1,x2,y2)) if x2>x1 and y2>y1 else img\n","\n","@torch.no_grad()\n","def clip_cleanliness(img: Image.Image) -> Dict[str,float]:\n","    texts = [\"a clean car photo\",\"a dirty, muddy car photo\"]\n","    inputs = CLIP_PROC(text=texts, images=img, return_tensors=\"pt\", padding=True).to(device)\n","    probs = CLIP_MODEL(**inputs).logits_per_image[0].softmax(dim=0).detach().cpu().numpy()\n","    return {\"clean\": float(probs[0]), \"dirty\": float(probs[1])}\n","\n","def quality_flags(img: Image.Image) -> Tuple[List[Tuple[str,str]], Dict[str,float]]:\n","    arr = np.array(img.convert(\"L\"))\n","    bright = float(arr.mean()); contrast = float(arr.std())\n","    pad = np.pad(arr, 1, mode=\"edge\")\n","    lap = (pad[:-2,1:-1] + pad[2:,1:-1] + pad[1:-1,:-2] + pad[1:-1,2:] - 4*arr)\n","    sharp = float(lap.var())\n","\n","    flags = []\n","    if bright < 70:  flags.append((\"low_light\",\"Низкая освещённость\"))\n","    if bright > 200: flags.append((\"overexp\",\"Пересвет\"))\n","    if contrast < 20:flags.append((\"low_contrast\",\"Низкий контраст\"))\n","    if sharp < 80:   flags.append((\"blurry\",\"Размыто\"))\n","    return flags, dict(bright=round(bright,1), contrast=round(contrast,1), sharp=round(sharp,1))\n","\n","def _predict_boxes(det, img, conf, names_map=None):\n","    out = []\n","    if det is None: return out\n","    res = det.predict(source=img, imgsz=640, conf=conf, verbose=False)\n","    for r in res:\n","        if getattr(r, \"boxes\", None) is None: continue\n","        for b in r.boxes:\n","            x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","            score = float(b.conf.item())\n","            cls_id = int(b.cls.item()) if hasattr(b,\"cls\") else -1\n","            raw = names_map.get(cls_id, str(cls_id)) if isinstance(names_map, dict) else None\n","            out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"raw_name\":raw})\n","    return out\n","\n","def detect_damage(img: Image.Image, conf: float, lang: str):\n","    boxes = []\n","    boxes += _predict_boxes(DMG1, img, conf, names_map=DMG1_NAMES)\n","    boxes += _predict_boxes(DMG2, img, conf, names_map=None)\n","\n","    vis = img.copy()\n","    draw = ImageDraw.Draw(vis)\n","    counts = {\"scratch\":0,\"dent\":0,\"rust\":0,\"dirt\":0,\"damage\":0}\n","\n","    for b in boxes:\n","        x1,y1,x2,y2 = b[\"xyxy\"]\n","        label = _norm_label(b.get(\"raw_name\",\"damage\"))\n","        counts[label] = counts.get(label,0) + 1\n","        # обводка\n","        draw.rectangle([x1,y1,x2,y2], outline=(34,197,94), width=3)  # inDrive-green\n","\n","    # «мягкая» классификация повреждений: severe/ minor / undamaged\n","    total = sum(counts.values())\n","    if total == 0:\n","        dmg_probs = {\"undamaged\":1.0, \"minor\":0.0, \"severe\":0.0}\n","    else:\n","        severe_cnt = counts.get(\"dent\",0) + counts.get(\"rust\",0)\n","        minor_cnt  = counts.get(\"scratch\",0) + counts.get(\"dirt\",0) + counts.get(\"damage\",0)\n","        s = max(0.0, float(severe_cnt)/total)\n","        m = max(0.0, float(minor_cnt)/total)\n","        u = max(0.0, 1.0 - s - m)\n","        dmg_probs = {\"undamaged\":u, \"minor\":m, \"severe\":s}\n","\n","    return boxes, vis, counts, dmg_probs\n","\n","def health_index(clean_label: str, counts: Dict[str,int], qflags: List[Tuple[str,str]]) -> int:\n","    score = 100\n","    damage_total = counts.get(\"scratch\",0)+counts.get(\"dent\",0)+counts.get(\"rust\",0)\n","    dirt_total   = counts.get(\"dirt\",0)\n","    score -= 12 * damage_total\n","    score -= 5  * dirt_total\n","    if clean_label == \"dirty\": score -= 10\n","    score -= 5 * len(qflags)\n","    return int(max(0,min(100,score)))\n","\n","def percent(x: float) -> str:\n","    return f\"{int(round(100*max(0.0,min(1.0,x))))}%\"\n","\n","def summary_html(lang: str, clean_probs, dmg_probs, counts, idx, qflags, status):\n","    if lang==\"ru\":\n","        t_clean = \"Чистота\"; t_dmg=\"Повреждения\"\n","        lab = {\"clean\":\"Чистый\",\"dirty\":\"Грязный\",\"undamaged\":\"Неповреждённый\",\"minor\":\"Незначительные\",\"severe\":\"Серьёзные\",\n","               \"index\":\"Индекс состояния\",\"q\":\"Нет замечаний\" if not qflags else \"Замечания\"}\n","        cnt_title=\"Счётчик дефектов\"; s_title=\"Итоговый статус\"\n","    else:\n","        t_clean = \"Cleanliness\"; t_dmg=\"Damage\"\n","        lab = {\"clean\":\"Clean\",\"dirty\":\"Dirty\",\"undamaged\":\"Undamaged\",\"minor\":\"Minor\",\"severe\":\"Severe\",\n","               \"index\":\"Health index\",\"q\":\"No warnings\" if not qflags else \"Warnings\"}\n","        cnt_title=\"Defect counter\"; s_title=\"Final status\"\n","\n","    lst=[]\n","    for k in (\"scratch\",\"dent\",\"rust\",\"dirt\",\"damage\"):\n","        v = counts.get(k,0)\n","        if v>0:\n","            name = (RU_LABEL if lang==\"ru\" else EN_LABEL).get(k,k)\n","            lst.append(f\"{name}: <b>{v}</b>\")\n","    line = \", \".join(lst) if lst else (\"—\" if lang==\"ru\" else \"—\")\n","    q_text = lab[\"q\"] if not qflags else \", \".join([t for _,t in qflags])\n","\n","    return f\"\"\"\n","    <div class=\"card kv\">\n","      <div class=\"sec\">📊 <b>{t_clean}</b></div>\n","      <div>{lab['clean']}: <b class='ok'>{percent(clean_probs['clean'])}</b></div>\n","      <div>{lab['dirty']}: <b class='warn'>{percent(clean_probs['dirty'])}</b></div>\n","      <div class=\"sep\"></div>\n","\n","      <div class=\"sec\">🔧 <b>{t_dmg}</b></div>\n","      <div>{lab['undamaged']}: <b class='ok'>{percent(dmg_probs['undamaged'])}</b></div>\n","      <div>{lab['minor']}: <b class='warn'>{percent(dmg_probs['minor'])}</b></div>\n","      <div>{lab['severe']}: <b class='bad'>{percent(dmg_probs['severe'])}</b></div>\n","\n","      <div class=\"sec\">{cnt_title}: <span>{line}</span></div>\n","      <div class=\"sec\">{lab['index']}: <b>{idx}/100</b></div>\n","      <div class=\"sec\">{lab['q']}: <span>{q_text}</span></div>\n","      <div class=\"sep\"></div>\n","      <div class=\"sec\"><b>{s_title}:</b> {status}</div>\n","    </div>\n","    \"\"\"\n","\n","# --------------------------------------------------\n","# Основной пайплайн\n","# --------------------------------------------------\n","def analyze(image: Image.Image, use_crop: bool, conf_thr: float, lang: str):\n","    if image is None:\n","        return None, \"\", \"\", \"\"\n","\n","    img = image.convert(\"RGB\")\n","    img_c = crop_car(img) if use_crop else img\n","\n","    qflags, qstats = quality_flags(img_c)\n","    clean = clip_cleanliness(img_c)\n","    clean_label = \"dirty\" if clean[\"dirty\"] > clean[\"clean\"] else \"clean\"\n","\n","    boxes, vis, counts, dmg_probs = detect_damage(img_c, float(conf_thr), lang)\n","    idx = health_index(clean_label, counts, qflags)\n","    status = (\"❌ Требуется осмотр\" if sum(counts.values())>0 else\n","              \"⚠️ Нужна мойка\" if clean_label==\"dirty\" else\n","              \"✅ Готово к размещению\")\n","\n","    summary = summary_html(lang, clean, dmg_probs, counts, idx, qflags, status)\n","\n","    report = {\n","        \"ts\": int(time.time()),\n","        \"status\": status,\n","        \"cleanliness_probs\": clean,\n","        \"damage_probs\": dmg_probs,\n","        \"defect_counts\": counts,\n","        \"damage_boxes\": boxes,\n","        \"quality_flags\": [t for _,t in qflags],\n","        \"quality_stats\": qstats,\n","        \"index_0_100\": idx\n","    }\n","    return vis, summary, json.dumps(report, ensure_ascii=False, indent=2), status\n","\n","# --------------------------------------------------\n","# UI\n","# --------------------------------------------------\n","with gr.Blocks(css=THEME_CSS, title=\"Оценка состояния автомобиля для inDrive\") as demo:\n","    gr.Markdown(\"<h1 class='title'>🚗 Оценка состояния автомобиля для inDrive</h1>\")\n","\n","    with gr.Row(elem_classes=[\"lang-row\"]):\n","        with gr.Column(scale=0, elem_id=\"lang-col\"):\n","            lang = gr.Dropdown(choices=[\"ru\",\"en\"], value=\"ru\", label=\"Язык / Language\")\n","        gr.Markdown(\"\")  # просто выравнивание\n","\n","    with gr.Row():\n","        with gr.Column(scale=6):\n","            in_img  = gr.Image(type=\"pil\", label=\"Фото автомобиля (1 изображение)\")\n","            with gr.Accordion(\"Настройки\", open=True):\n","                usecrop = gr.Checkbox(value=True, label=\"Кропать авто (YOLO)\")\n","                conf    = gr.Slider(0.1, 0.7, value=0.35, step=0.05, label=\"Порог уверенности повреждений\")\n","                with gr.Row():\n","                    gr.Button(\"0.25\").click(lambda: gr.update(value=0.25), None, conf)\n","                    gr.Button(\"0.35\").click(lambda: gr.update(value=0.35), None, conf)\n","                    gr.Button(\"0.45\").click(lambda: gr.update(value=0.45), None, conf)\n","            run = gr.Button(\"Анализировать\", elem_classes=[\"primary-btn\"])\n","        with gr.Column(scale=6):\n","            summary_html_out = gr.HTML()\n","            with gr.Accordion(\"Разметка (боксы)\", open=False):\n","                out_img = gr.Image(label=None, elem_classes=[\"box-preview\"])\n","            out_json = gr.Code(label=\"Отчёт (JSON)\", language=\"json\")\n","            status   = gr.Textbox(label=\"Итоговый статус\", interactive=False)\n","\n","    run.click(analyze, inputs=[in_img, usecrop, conf, lang],\n","              outputs=[out_img, summary_html_out, out_json, status])\n","\n","    gr.Markdown(\"<div class='footer'>Сделано с любовью от команды <b>DOGS</b> для inDrive</div>\")\n","\n","if __name__ == \"__main__\":\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":764,"referenced_widgets":["e93ea448f3784241b51e2a8567066b57","017a462fdfc34ea3bafecc2d530773bb","5c782495c895434fa284d6fc5e8d2f09","c6178d4698d246c1ba8438d6c1e6413b","4c4e8122e2a74295904e578197ae3cf7","db48a8c9c90b41b2a3ffac7ec75c9048","f170150817f54afa9f14437f8979a71f","36853b64cb974fa4a7e5c49109ccbefd","e43aa3ce774f4708a1542a5992b63a9e","576194f6c01e437b876c04efac558493","1f24af5f162042cbaa63358a5d786eae"]},"id":"UBF_bfegoyDT","executionInfo":{"status":"ok","timestamp":1757860313539,"user_tz":-300,"elapsed":17237,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"e67f870e-78ce-41f5-8436-270935f19d2c"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"]},{"output_type":"display_data","data":{"text/plain":["Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e93ea448f3784241b51e2a8567066b57"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://96a685af6f5351bc5b.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://96a685af6f5351bc5b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}}]},{"cell_type":"code","source":["%%writefile app.py\n","import os\n","import gradio as gr\n","from PIL import Image, ImageDraw, ImageFont\n","import torch\n","from transformers import CLIPProcessor, CLIPModel\n","import numpy as np\n","\n","# ---------- Сохранение отчёта в JSON ----------\n","def save_json_file(report):\n","    import json, time\n","    name = f\"report_{int(time.time())}.json\"\n","    with open(name, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(report, f, indent=2, ensure_ascii=False)\n","    return name\n","# ----------------------------------------------\n","\n","# 1) YOLO для КРОПА авто (COCO)\n","crop_yolo = None\n","try:\n","    from ultralytics import YOLO\n","    crop_yolo = YOLO(\"yolov8n.pt\")\n","except Exception:\n","    crop_yolo = None\n","\n","# 2) YOLO для ПОВРЕЖДЕНИЙ (основные веса)\n","damage_yolo = None\n","damage_names = None\n","if os.path.exists(\"/content/weights/damage.pt\"):\n","    try:\n","        from ultralytics import YOLO\n","        damage_yolo = YOLO(\"/content/weights/damage.pt\")\n","        try:\n","            damage_names = damage_yolo.model.names if hasattr(damage_yolo, \"model\") else damage_yolo.names\n","        except Exception:\n","            damage_names = None\n","    except Exception:\n","        damage_yolo = None\n","\n","# нормализация кривых меток\n","def normalize_label(name: str) -> str:\n","    n = str(name).lower()\n","    if n == \"dunt\":    return \"dent\"\n","    if n == \"scracth\": return \"scratch\"\n","    return n\n","\n","# Русские подписи классов\n","RU_LABEL = {\n","    \"scratch\": \"царапина\",\n","    \"dent\":    \"вмятина\",\n","    \"rust\":    \"ржавчина\",\n","    \"car\":     \"авто\",\n","}\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n","clip_proc  = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","cleanliness_texts = [\"a clean car photo\",\"a dirty, muddy car photo\"]\n","\n","def crop_car(img: Image.Image) -> Image.Image:\n","    if crop_yolo is None:\n","        return img\n","    res = crop_yolo.predict(source=img, imgsz=640, conf=0.25, verbose=False)\n","    if not res: return img\n","    best_area, best_box = 0, None\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            try:\n","                if int(b.cls.item()) != 2:  # 2 = 'car' в COCO\n","                    continue\n","                x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","                area = (x2-x1)*(y2-y1)\n","                if area > best_area:\n","                    best_area, best_box = area, (x1,y1,x2,y2)\n","            except:\n","                pass\n","    if best_box is None: return img\n","    x1,y1,x2,y2 = best_box\n","    x1=max(0,x1); y1=max(0,y1); x2=min(img.width,x2); y2=min(img.height,y2)\n","    return img.crop((x1,y1,x2,y2)) if x2>x1 and y2>y1 else img\n","\n","@torch.no_grad()\n","def clip_cleanliness(img: Image.Image):\n","    inputs = clip_proc(text=cleanliness_texts, images=img, return_tensors=\"pt\", padding=True).to(device)\n","    probs = clip_model(**inputs).logits_per_image[0].softmax(dim=0).detach().cpu().numpy()\n","    idx = int(np.argmax(probs))\n","    return [\"clean\",\"dirty\"][idx], {t: float(p) for t,p in zip(cleanliness_texts, probs)}\n","\n","def quality_flags(img: Image.Image):\n","    # Простая оценка качества кадра\n","    arr = np.array(img.convert(\"L\"))\n","    bright = arr.mean()\n","    contrast = arr.std()\n","    pad = np.pad(arr, 1, mode=\"edge\")\n","    lap = (pad[:-2,1:-1] + pad[2:,1:-1] + pad[1:-1,:-2] + pad[1:-1,2:] - 4*arr)\n","    sharp = float(lap.var())\n","\n","    flags = []\n","    if bright < 70:  flags.append(\"low_light\")\n","    if bright > 200: flags.append(\"overexposed\")\n","    if contrast < 20:flags.append(\"low_contrast\")\n","    if sharp < 80:   flags.append(\"blurry\")\n","    stats = dict(bright=round(float(bright),1), contrast=round(float(contrast),1), sharp=round(sharp,1))\n","    return flags, stats\n","\n","def quality_tips(flags):\n","    tips = []\n","    if \"low_light\" in flags:   tips.append(\"Снимай при дневном свете или включи вспышку.\")\n","    if \"overexposed\" in flags: tips.append(\"Убери блики: смени угол или отойди на 30–50 см.\")\n","    if \"low_contrast\" in flags:tips.append(\"Подойди ближе — заполни кадр машиной.\")\n","    if \"blurry\" in flags:      tips.append(\"Дай автофокусу сработать: задержи телефон на 1 секунду.\")\n","    return tips\n","\n","COLOR_MAP = {\n","    \"scratch\": (255,   0,   0),\n","    \"dent\":    (255, 140,   0),\n","    \"rust\":    (255, 215,   0),\n","    \"car\":     (  0, 255,   0),\n","}\n","\n","def draw_label(draw: ImageDraw.ImageDraw, xy, text, color):\n","    x1,y1,x2,y2 = xy\n","    try:\n","        font = ImageFont.load_default()\n","        tw = int(draw.textlength(text, font=font))\n","        th = 12\n","    except:\n","        font = None\n","        tw, th = 60, 12\n","    pad = 2\n","    bx2 = x1 + tw + pad*2\n","    by2 = y1 + th + pad*2\n","    draw.rectangle([x1, y1, bx2, by2], fill=color)\n","    draw.text((x1+pad, y1+pad), text, fill=(0,0,0), font=font)\n","\n","def run_detector(detector, img: Image.Image, conf_thr=0.35):\n","    if detector is None:\n","        return []\n","    res = detector.predict(source=img, imgsz=640, conf=conf_thr, verbose=False)\n","    out = []\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","            score = float(b.conf.item())\n","            cls_id = int(b.cls.item()) if hasattr(b, \"cls\") else -1\n","            raw_name = damage_names.get(cls_id, str(cls_id)) if isinstance(damage_names, dict) else str(cls_id)\n","            out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"cls\":cls_id, \"raw_name\": raw_name})\n","    return out\n","\n","def detect_damage(img: Image.Image, conf_thr=0.35):\n","    boxes_all = run_detector(damage_yolo, img, conf_thr)\n","    vis = img.copy()\n","    draw = ImageDraw.Draw(vis)\n","    boxes_out = []\n","    for b in boxes_all:\n","        x1,y1,x2,y2 = b[\"xyxy\"]\n","        score = b[\"score\"]\n","        label = normalize_label(b.get(\"raw_name\",\"damage\"))\n","        ru = RU_LABEL.get(label, label)\n","        color = COLOR_MAP.get(label, (0, 200, 255))\n","        draw.rectangle([x1,y1,x2,y2], width=3, outline=color)\n","        draw_label(draw, (x1,y1,x2,y2), f\"{ru} {score:.2f}\", color)\n","        boxes_out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"label\":label})\n","    return boxes_out, vis\n","\n","def compute_counts(dmg_boxes):\n","    counts = {}\n","    for b in dmg_boxes:\n","        lbl = b[\"label\"]\n","        if lbl == \"car\":\n","            continue\n","        counts[lbl] = counts.get(lbl, 0) + 1\n","    return counts\n","\n","def final_status(cleanliness, dmg_boxes, qflags):\n","    if any(b[\"label\"] in (\"scratch\",\"dent\",\"rust\") for b in dmg_boxes):\n","        return \"❌ повреждена — требуется осмотр\"\n","    if \"blurry\" in qflags or \"low_light\" in qflags:\n","        return \"⚠️ низкое качество — сделайте новое фото\"\n","    if cleanliness == \"dirty\":\n","        return \"⚠️ нужна мойка\"\n","    return \"✅ ок — готово\"\n","\n","def health_score(cleanliness, dmg_counts, qflags):\n","    score = 100\n","    score -= 12 * sum(dmg_counts.values())\n","    if cleanliness == \"dirty\": score -= 10\n","    score -= 5 * len(qflags)\n","    score = int(max(0, min(100, score)))\n","    return score\n","\n","def acceptable(status):\n","    # допустимо к размещению, если «ок» или только «нужна мойка»\n","    return status.startswith(\"✅\") or status.startswith(\"⚠️ нужна мойка\")\n","\n","def counts_ru_text(counts_ru: dict) -> str:\n","    if not counts_ru:\n","        return \"Нет выявленных дефектов.\"\n","    lines = [f\"- {k}: {v}\" for k, v in counts_ru.items()]\n","    return \"\\n\".join(lines)\n","\n","def predict(image: Image.Image, use_yolo_crop: bool, conf_thr: float):\n","    if image is None:\n","        return {\"error\":\"Загрузите фото\"}, None, None, None, None, None, None, None, None, None\n","    img = image.convert(\"RGB\")\n","    cropped = crop_car(img) if use_yolo_crop else img\n","\n","    qflags, qstats = quality_flags(cropped)\n","    tips = quality_tips(qflags)\n","    clean_label, clean_scores = clip_cleanliness(cropped)\n","    dmg_boxes, vis = detect_damage(cropped, conf_thr=conf_thr)\n","\n","    damage_label = \"damaged\" if any(b[\"label\"] in (\"scratch\",\"dent\",\"rust\") for b in dmg_boxes) else \"undamaged\"\n","    counts_en = compute_counts(dmg_boxes)\n","    counts_ru = {RU_LABEL.get(k, k): v for k, v in counts_en.items()}\n","    counts_ru_md = counts_ru_text(counts_ru)\n","\n","    score = health_score(clean_label, counts_en, qflags)\n","    status = final_status(clean_label, dmg_boxes, qflags)\n","    acceptable_flag = acceptable(status)\n","\n","    report = {\n","        \"status\": status,\n","        \"acceptable_for_listing\": acceptable_flag,\n","        \"health_score\": score,\n","        \"cleanliness\": clean_label,          # 'clean' | 'dirty'\n","        \"damage\": damage_label,              # 'damaged' | 'undamaged'\n","        \"damage_counts\": counts_en,          # англ. ключи (для интеграции)\n","        \"damage_counts_ru\": counts_ru,       # для UI/питча\n","        \"damage_boxes\": dmg_boxes,\n","        \"quality_flags\": qflags,\n","        \"quality_stats\": qstats,\n","        \"quality_tips\": tips\n","    }\n","    tips_text = (\"• \" + \"\\n• \".join(tips)) if tips else \"—\"\n","    return report, vis, (\"чистая\" if clean_label==\"clean\" else \"грязная\"), \\\n","           (\"повреждена\" if damage_label==\"damaged\" else \"без повреждений\"), \\\n","           status, counts_ru, counts_ru_md, score, tips_text, acceptable_flag\n","\n","# ---------- UI ----------\n","with gr.Blocks() as demo:\n","    gr.Markdown(\"# AI inDrive — состояние авто (объяснимость + отчёт)\")\n","    gr.Markdown(\"Кроп авто → чистота (CLIP) → повреждения (YOLO, боксы с подписями) → Quality Gate → Индекс состояния → итоговый статус → экспорт JSON\")\n","\n","    with gr.Row():\n","        with gr.Column():\n","            in_img   = gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля\")\n","            usecrop  = gr.Checkbox(value=True, label=\"Кропать авто (YOLO)\")\n","            conf     = gr.Slider(0.1, 0.7, value=0.35, step=0.05, label=\"Порог уверенности повреждений\")\n","            # пресеты порога — в порядке возрастания и одинаковая ширина\n","            with gr.Row():\n","                with gr.Column(scale=1):\n","                    btn_aggr = gr.Button(\"Агрессивный (0.25)\")\n","                with gr.Column(scale=1):\n","                    btn_bal  = gr.Button(\"Сбалансированный (0.35)\")\n","                with gr.Column(scale=1):\n","                    btn_cons = gr.Button(\"Консервативный (0.45)\")\n","            btn      = gr.Button(\"Анализ\")\n","        with gr.Column():\n","            out_json = gr.JSON(label=\"Отчёт (JSON)\")\n","            save_btn  = gr.Button(\"Скачать JSON\")\n","            save_file = gr.File(label=\"Файл отчёта\")\n","            out_img  = gr.Image(label=\"Кадр с боксами\")\n","            clean_txt= gr.Textbox(label=\"Чистота\", interactive=False)\n","            dmg_txt  = gr.Textbox(label=\"Повреждения\", interactive=False)\n","            status   = gr.Textbox(label=\"Итоговый статус\", interactive=False)\n","            counts_j = gr.JSON(label=\"Счётчик дефектов (JSON, РУС)\")\n","            counts_md= gr.Markdown(\"—\")  # человеко-понятный вид\n","            score_ui = gr.Slider(0, 100, value=100, step=1, label=\"Индекс состояния (0–100)\", interactive=False)\n","            tips_md  = gr.Markdown(\"Подсказки по качеству появятся здесь\")\n","            ok_flag  = gr.Checkbox(value=False, label=\"Готово к размещению\", interactive=False)\n","\n","    # Основная кнопка\n","    btn.click(\n","        predict,\n","        inputs=[in_img, usecrop, conf],\n","        outputs=[out_json, out_img, clean_txt, dmg_txt, status, counts_j, counts_md, score_ui, tips_md, ok_flag]\n","    )\n","\n","    # Пресеты порогов\n","    btn_aggr.click(lambda: 0.25, outputs=[conf])\n","    btn_bal.click(lambda: 0.35, outputs=[conf])\n","    btn_cons.click(lambda: 0.45, outputs=[conf])\n","\n","    # Сохранение отчёта\n","    save_btn.click(save_json_file, inputs=[out_json], outputs=[save_file])\n","\n","if __name__ == \"__main__\":\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fY-YR4rmqjZG","executionInfo":{"status":"ok","timestamp":1757860750716,"user_tz":-300,"elapsed":114,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"e6c8ab72-f1d9-47cc-ece3-6795c94d39a9"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/indrive_hack/app.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"REWA8ybvqq1N","executionInfo":{"status":"ok","timestamp":1757860794847,"user_tz":-300,"elapsed":22908,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"b720f667-8a3f-4718-8fa4-9c6923ac1f29"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1757860782.440335   37257 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1757860782.447080   37257 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1757860782.463556   37257 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757860782.463594   37257 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757860782.463598   37257 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1757860782.463604   37257 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","Fetching 1 files: 100% 1/1 [00:00<00:00, 12595.51it/s]\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/indrive_hack/app.py\", line 278, in <module>\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2794, in launch\n","    ) = http_server.start_server(\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/gradio/http_server.py\", line 157, in start_server\n","    raise OSError(\n","OSError: Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import os\n","import gradio as gr\n","from PIL import Image, ImageDraw, ImageFont\n","import torch\n","from transformers import CLIPProcessor, CLIPModel\n","import numpy as np\n","\n","# ---------- Пути ----------\n","DRIVE_ROOT = \"/content/drive/MyDrive/indrive_hack\"\n","DRIVE_WEI  = f\"{DRIVE_ROOT}/weights\"\n","DRIVE_REP  = f\"{DRIVE_ROOT}/reports\"\n","os.makedirs(DRIVE_REP, exist_ok=True)\n","\n","# ---------- Сохранение отчёта в JSON (теперь в Drive) ----------\n","def save_json_file(report):\n","    import json, time\n","    name = f\"report_{int(time.time())}.json\"\n","    path = os.path.join(DRIVE_REP, name)\n","    with open(path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(report, f, indent=2, ensure_ascii=False)\n","    return path\n","# ----------------------------------------------\n","\n","# 1) YOLO для КРОПА авто (COCO)\n","crop_yolo = None\n","try:\n","    from ultralytics import YOLO\n","    crop_yolo = YOLO(\"yolov8n.pt\")\n","except Exception:\n","    crop_yolo = None\n","\n","# 2) YOLO для ПОВРЕЖДЕНИЙ — теперь ДВЕ модели\n","#    Будем искать веса в /content/weights ИЛИ в Drive\n","def _first_existing(*paths):\n","    for p in paths:\n","        if p and os.path.exists(p):\n","            return p\n","    return None\n","\n","damage_yolo1 = None     # например, damage.pt или damage_rust.pt\n","damage_yolo2 = None     # вторая модель, например damage_v2.pt\n","damage_names1 = None\n","\n","p1 = _first_existing(\n","    \"/content/weights/damage.pt\",\n","    \"/content/weights/damage_rust.pt\",\n","    f\"{DRIVE_WEI}/damage.pt\",\n","    f\"{DRIVE_WEI}/damage_rust.pt\",\n",")\n","p2 = _first_existing(\n","    \"/content/weights/damage_v2.pt\",\n","    f\"{DRIVE_WEI}/damage_v2.pt\",\n",")\n","\n","try:\n","    from ultralytics import YOLO\n","    if p1:\n","        damage_yolo1 = YOLO(p1)\n","        try:\n","            damage_names1 = damage_yolo1.model.names if hasattr(damage_yolo1, \"model\") else damage_yolo1.names\n","        except Exception:\n","            damage_names1 = None\n","    if p2:\n","        damage_yolo2 = YOLO(p2)\n","except Exception:\n","    damage_yolo1, damage_yolo2 = None, None\n","    damage_names1 = None\n","\n","# нормализация кривых меток\n","def normalize_label(name: str) -> str:\n","    n = str(name).lower()\n","    if n == \"dunt\":    return \"dent\"\n","    if n == \"scracth\": return \"scratch\"\n","    # на всякий случай\n","    if \"scr\" in n:     return \"scratch\"\n","    return n\n","\n","# Русские подписи классов\n","RU_LABEL = {\n","    \"scratch\": \"царапина\",\n","    \"dent\":    \"вмятина\",\n","    \"rust\":    \"ржавчина\",\n","    \"car\":     \"авто\",\n","}\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n","clip_proc  = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","cleanliness_texts = [\"a clean car photo\",\"a dirty, muddy car photo\"]\n","\n","def crop_car(img: Image.Image) -> Image.Image:\n","    if crop_yolo is None:\n","        return img\n","    res = crop_yolo.predict(source=img, imgsz=640, conf=0.25, verbose=False)\n","    if not res: return img\n","    best_area, best_box = 0, None\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            try:\n","                if int(b.cls.item()) != 2:  # 2 = 'car' в COCO\n","                    continue\n","                x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","                area = (x2-x1)*(y2-y1)\n","                if area > best_area:\n","                    best_area, best_box = area, (x1,y1,x2,y2)\n","            except:\n","                pass\n","    if best_box is None: return img\n","    x1,y1,x2,y2 = best_box\n","    x1=max(0,x1); y1=max(0,y1); x2=min(img.width,x2); y2=min(img.height,y2)\n","    return img.crop((x1,y1,x2,y2)) if x2>x1 and y2>y1 else img\n","\n","@torch.no_grad()\n","def clip_cleanliness(img: Image.Image):\n","    inputs = clip_proc(text=cleanliness_texts, images=img, return_tensors=\"pt\", padding=True).to(device)\n","    probs = clip_model(**inputs).logits_per_image[0].softmax(dim=0).detach().cpu().numpy()\n","    idx = int(np.argmax(probs))\n","    return [\"clean\",\"dirty\"][idx], {t: float(p) for t,p in zip(cleanliness_texts, probs)}\n","\n","def quality_flags(img: Image.Image):\n","    # Простая оценка качества кадра\n","    arr = np.array(img.convert(\"L\"))\n","    bright = arr.mean()\n","    contrast = arr.std()\n","    pad = np.pad(arr, 1, mode=\"edge\")\n","    lap = (pad[:-2,1:-1] + pad[2:,1:-1] + pad[1:-1,:-2] + pad[1:-1,2:] - 4*arr)\n","    sharp = float(lap.var())\n","\n","    flags = []\n","    if bright < 70:  flags.append(\"low_light\")\n","    if bright > 200: flags.append(\"overexposed\")\n","    if contrast < 20:flags.append(\"low_contrast\")\n","    if sharp < 80:   flags.append(\"blurry\")\n","    stats = dict(bright=round(float(bright),1), contrast=round(float(contrast),1), sharp=round(sharp,1))\n","    return flags, stats\n","\n","def quality_tips(flags):\n","    tips = []\n","    if \"low_light\" in flags:   tips.append(\"Снимай при дневном свете или включи вспышку.\")\n","    if \"overexposed\" in flags: tips.append(\"Убери блики: смени угол или отойди на 30–50 см.\")\n","    if \"low_contrast\" in flags:tips.append(\"Подойди ближе — заполни кадр машиной.\")\n","    if \"blurry\" in flags:      tips.append(\"Дай автофокусу сработать: задержи телефон на 1 секунду.\")\n","    return tips\n","\n","COLOR_MAP = {\n","    \"scratch\": (255,   0,   0),\n","    \"dent\":    (255, 140,   0),\n","    \"rust\":    (255, 215,   0),\n","    \"car\":     (  0, 255,   0),\n","}\n","\n","def draw_label(draw: ImageDraw.ImageDraw, xy, text, color):\n","    x1,y1,x2,y2 = xy\n","    try:\n","        font = ImageFont.load_default()\n","        tw = int(draw.textlength(text, font=font))\n","        th = 12\n","    except:\n","        font = None\n","        tw, th = 60, 12\n","    pad = 2\n","    bx2 = x1 + tw + pad*2\n","    by2 = y1 + th + pad*2\n","    draw.rectangle([x1, y1, bx2, by2], fill=color)\n","    draw.text((x1+pad, y1+pad), text, fill=(0,0,0), font=font)\n","\n","def _run_detector(detector, img: Image.Image, conf_thr=0.35, names_map=None):\n","    if detector is None:\n","        return []\n","    res = detector.predict(source=img, imgsz=640, conf=conf_thr, verbose=False)\n","    out = []\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","            score = float(b.conf.item())\n","            cls_id = int(b.cls.item()) if hasattr(b, \"cls\") else -1\n","            raw_name = None\n","            if isinstance(names_map, dict):\n","                raw_name = names_map.get(cls_id, str(cls_id))\n","            out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"cls\":cls_id, \"raw_name\": raw_name})\n","    return out\n","\n","def detect_damage(img: Image.Image, conf_thr=0.35):\n","    # Объединяем боксы от двух моделей\n","    boxes_all = []\n","    boxes_all += _run_detector(damage_yolo1, img, conf_thr, names_map=damage_names1)\n","    boxes_all += _run_detector(damage_yolo2, img, conf_thr, names_map=None)\n","\n","    vis = img.copy()\n","    draw = ImageDraw.Draw(vis)\n","    boxes_out = []\n","    for b in boxes_all:\n","        x1,y1,x2,y2 = b[\"xyxy\"]\n","        score = b[\"score\"]\n","        raw = b.get(\"raw_name\", \"damage\")\n","        label = normalize_label(raw)\n","        ru = RU_LABEL.get(label, label)\n","        color = COLOR_MAP.get(label, (0, 200, 255))\n","        draw.rectangle([x1,y1,x2,y2], width=3, outline=color)\n","        draw_label(draw, (x1,y1,x2,y2), f\"{ru} {score:.2f}\", color)\n","        boxes_out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"label\":label})\n","    return boxes_out, vis\n","\n","def compute_counts(dmg_boxes):\n","    counts = {}\n","    for b in dmg_boxes:\n","        lbl = b[\"label\"]\n","        if lbl == \"car\":\n","            continue\n","        counts[lbl] = counts.get(lbl, 0) + 1\n","    return counts\n","\n","def final_status(cleanliness, dmg_boxes, qflags):\n","    if any(b[\"label\"] in (\"scratch\",\"dent\",\"rust\") for b in dmg_boxes):\n","        return \"❌ повреждена — требуется осмотр\"\n","    if \"blurry\" in qflags or \"low_light\" in qflags:\n","        return \"⚠️ низкое качество — сделайте новое фото\"\n","    if cleanliness == \"dirty\":\n","        return \"⚠️ нужна мойка\"\n","    return \"✅ ок — готово\"\n","\n","def health_score(cleanliness, dmg_counts, qflags):\n","    score = 100\n","    score -= 12 * sum(dmg_counts.values())\n","    if cleanliness == \"dirty\": score -= 10\n","    score -= 5 * len(qflags)\n","    score = int(max(0, min(100, score)))\n","    return score\n","\n","def acceptable(status):\n","    # допустимо к размещению, если «ок» или только «нужна мойка»\n","    return status.startswith(\"✅\") or status.startswith(\"⚠️ нужна мойка\")\n","\n","def counts_ru_text(counts_ru: dict) -> str:\n","    if not counts_ru:\n","        return \"Нет выявленных дефектов.\"\n","    lines = [f\"- {k}: {v}\" for k, v in counts_ru.items()]\n","    return \"\\n\".join(lines)\n","\n","def predict(image: Image.Image, use_yolo_crop: bool, conf_thr: float):\n","    if image is None:\n","        return {\"error\":\"Загрузите фото\"}, None, None, None, None, None, None, None, None, None\n","    img = image.convert(\"RGB\")\n","    cropped = crop_car(img) if use_yolo_crop else img\n","\n","    qflags, qstats = quality_flags(cropped)\n","    tips = quality_tips(qflags)\n","    clean_label, clean_scores = clip_cleanliness(cropped)\n","    dmg_boxes, vis = detect_damage(cropped, conf_thr=conf_thr)\n","\n","    damage_label = \"damaged\" if any(b[\"label\"] in (\"scratch\",\"dent\",\"rust\") for b in dmg_boxes) else \"undamaged\"\n","    counts_en = compute_counts(dmg_boxes)\n","    counts_ru = {RU_LABEL.get(k, k): v for k, v in counts_en.items()}\n","    counts_ru_md = counts_ru_text(counts_ru)\n","\n","    score = health_score(clean_label, counts_en, qflags)\n","    status = final_status(clean_label, dmg_boxes, qflags)\n","    acceptable_flag = acceptable(status)\n","\n","    report = {\n","        \"status\": status,\n","        \"acceptable_for_listing\": acceptable_flag,\n","        \"health_score\": score,\n","        \"cleanliness\": clean_label,          # 'clean' | 'dirty'\n","        \"damage\": damage_label,              # 'damaged' | 'undamaged'\n","        \"damage_counts\": counts_en,          # англ. ключи (для интеграции)\n","        \"damage_counts_ru\": counts_ru,       # для UI/питча\n","        \"damage_boxes\": dmg_boxes,\n","        \"quality_flags\": qflags,\n","        \"quality_stats\": qstats,\n","        \"quality_tips\": tips\n","    }\n","    tips_text = (\"• \" + \"\\n• \".join(tips)) if tips else \"—\"\n","    return report, vis, (\"чистая\" if clean_label==\"clean\" else \"грязная\"), \\\n","           (\"повреждена\" if damage_label==\"damaged\" else \"без повреждений\"), \\\n","           status, counts_ru, counts_ru_md, score, tips_text, acceptable_flag\n","\n","# ---------- UI ----------\n","with gr.Blocks() as demo:\n","    gr.Markdown(\"# Оценка состояния автомобиля для inDrive\")\n","    gr.Markdown(\"Кроп авто → чистота (CLIP) → повреждения (две YOLO) → Quality Gate → Индекс → статус → экспорт JSON\")\n","\n","    with gr.Row():\n","        with gr.Column():\n","            in_img   = gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля\")\n","            usecrop  = gr.Checkbox(value=True, label=\"Кропать авто (YOLO)\")\n","            conf     = gr.Slider(0.1, 0.7, value=0.35, step=0.05, label=\"Порог уверенности повреждений\")\n","            with gr.Row():\n","                with gr.Column(scale=1):\n","                    btn_aggr = gr.Button(\"Агрессивный (0.25)\")\n","                with gr.Column(scale=1):\n","                    btn_bal  = gr.Button(\"Сбалансированный (0.35)\")\n","                with gr.Column(scale=1):\n","                    btn_cons = gr.Button(\"Консервативный (0.45)\")\n","            btn      = gr.Button(\"Анализ\")\n","        with gr.Column():\n","            out_json = gr.JSON(label=\"Отчёт (JSON)\")\n","            save_btn  = gr.Button(\"Скачать JSON\")\n","            save_file = gr.File(label=\"Файл отчёта\")\n","            out_img  = gr.Image(label=\"Кадр с боксами\")\n","            clean_txt= gr.Textbox(label=\"Чистота\", interactive=False)\n","            dmg_txt  = gr.Textbox(label=\"Повреждения\", interactive=False)\n","            status   = gr.Textbox(label=\"Итоговый статус\", interactive=False)\n","            counts_j = gr.JSON(label=\"Счётчик дефектов (JSON, РУС)\")\n","            counts_md= gr.Markdown(\"—\")  # человеко-понятный вид\n","            score_ui = gr.Slider(0, 100, value=100, step=1, label=\"Индекс состояния (0–100)\", interactive=False)\n","            tips_md  = gr.Markdown(\"Подсказки по качеству появятся здесь\")\n","            ok_flag  = gr.Checkbox(value=False, label=\"Готово к размещению\", interactive=False)\n","\n","    # Основная кнопка\n","    btn.click(\n","        predict,\n","        inputs=[in_img, usecrop, conf],\n","        outputs=[out_json, out_img, clean_txt, dmg_txt, status, counts_j, counts_md, score_ui, tips_md, ok_flag]\n","    )\n","\n","    # Пресеты порогов\n","    btn_aggr.click(lambda: 0.25, outputs=[conf])\n","    btn_bal.click(lambda: 0.35, outputs=[conf])\n","    btn_cons.click(lambda: 0.45, outputs=[conf])\n","\n","    # Сохранение отчёта (в Drive)\n","    save_btn.click(save_json_file, inputs=[out_json], outputs=[save_file])\n","\n","    gr.Markdown(\"<div style='opacity:.7;margin-top:10px;font-size:12px'>Сделано с любовью от команды <b>DOGS</b> для inDrive</div>\")\n","\n","if __name__ == \"__main__\":\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"is_5T9EUsbH_","executionInfo":{"status":"ok","timestamp":1757861301053,"user_tz":-300,"elapsed":84,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"e93d8022-2c60-4206-ece9-a71b689f1fa2"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["# %%writefile /content/drive/MyDrive/indrive_hack/app.py\n","import os\n","import gradio as gr\n","from PIL import Image, ImageDraw, ImageFont\n","import torch\n","from transformers import CLIPProcessor, CLIPModel\n","import numpy as np\n","\n","# ---------- Пути ----------\n","DRIVE_ROOT = \"/content/drive/MyDrive/indrive_hack\"\n","DRIVE_WEI  = f\"{DRIVE_ROOT}/weights\"\n","DRIVE_REP  = f\"{DRIVE_ROOT}/reports\"\n","os.makedirs(DRIVE_REP, exist_ok=True)\n","\n","# ---------- Сохранение отчёта в JSON (теперь в Drive) ----------\n","def save_json_file(report):\n","    import json, time\n","    name = f\"report_{int(time.time())}.json\"\n","    path = os.path.join(DRIVE_REP, name)\n","    with open(path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(report, f, indent=2, ensure_ascii=False)\n","    return path\n","# ----------------------------------------------\n","\n","# 1) YOLO для КРОПА авто (COCO)\n","crop_yolo = None\n","try:\n","    from ultralytics import YOLO\n","    crop_yolo = YOLO(\"yolov8n.pt\")\n","except Exception:\n","    crop_yolo = None\n","\n","# 2) YOLO для ПОВРЕЖДЕНИЙ — теперь ДВЕ модели\n","#    Будем искать веса в /content/weights ИЛИ в Drive\n","def _first_existing(*paths):\n","    for p in paths:\n","        if p and os.path.exists(p):\n","            return p\n","    return None\n","\n","damage_yolo1 = None     # например, damage.pt или damage_rust.pt\n","damage_yolo2 = None     # вторая модель, например damage_v2.pt\n","damage_names1 = None\n","\n","p1 = _first_existing(\n","    \"/content/weights/damage.pt\",\n","    \"/content/weights/damage_rust.pt\",\n","    f\"{DRIVE_WEI}/damage.pt\",\n","    f\"{DRIVE_WEI}/damage_rust.pt\",\n",")\n","p2 = _first_existing(\n","    \"/content/weights/damage_v2.pt\",\n","    f\"{DRIVE_WEI}/damage_v2.pt\",\n",")\n","\n","try:\n","    from ultralytics import YOLO\n","    if p1:\n","        damage_yolo1 = YOLO(p1)\n","        try:\n","            damage_names1 = damage_yolo1.model.names if hasattr(damage_yolo1, \"model\") else damage_yolo1.names\n","        except Exception:\n","            damage_names1 = None\n","    if p2:\n","        damage_yolo2 = YOLO(p2)\n","except Exception:\n","    damage_yolo1, damage_yolo2 = None, None\n","    damage_names1 = None\n","\n","# нормализация кривых меток\n","def normalize_label(name: str) -> str:\n","    n = str(name).lower()\n","    if n == \"dunt\":    return \"dent\"\n","    if n == \"scracth\": return \"scratch\"\n","    # на всякий случай\n","    if \"scr\" in n:     return \"scratch\"\n","    return n\n","\n","# Русские подписи классов\n","RU_LABEL = {\n","    \"scratch\": \"царапина\",\n","    \"dent\":    \"вмятина\",\n","    \"rust\":    \"ржавчина\",\n","    \"car\":     \"авто\",\n","}\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n","clip_proc  = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","cleanliness_texts = [\"a clean car photo\",\"a dirty, muddy car photo\"]\n","\n","def crop_car(img: Image.Image) -> Image.Image:\n","    if crop_yolo is None:\n","        return img\n","    res = crop_yolo.predict(source=img, imgsz=640, conf=0.25, verbose=False)\n","    if not res: return img\n","    best_area, best_box = 0, None\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            try:\n","                if int(b.cls.item()) != 2:  # 2 = 'car' в COCO\n","                    continue\n","                x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","                area = (x2-x1)*(y2-y1)\n","                if area > best_area:\n","                    best_area, best_box = area, (x1,y1,x2,y2)\n","            except:\n","                pass\n","    if best_box is None: return img\n","    x1,y1,x2,y2 = best_box\n","    x1=max(0,x1); y1=max(0,y1); x2=min(img.width,x2); y2=min(img.height,y2)\n","    return img.crop((x1,y1,x2,y2)) if x2>x1 and y2>y1 else img\n","\n","@torch.no_grad()\n","def clip_cleanliness(img: Image.Image):\n","    inputs = clip_proc(text=cleanliness_texts, images=img, return_tensors=\"pt\", padding=True).to(device)\n","    probs = clip_model(**inputs).logits_per_image[0].softmax(dim=0).detach().cpu().numpy()\n","    idx = int(np.argmax(probs))\n","    return [\"clean\",\"dirty\"][idx], {t: float(p) for t,p in zip(cleanliness_texts, probs)}\n","\n","def quality_flags(img: Image.Image):\n","    # Простая оценка качества кадра\n","    arr = np.array(img.convert(\"L\"))\n","    bright = arr.mean()\n","    contrast = arr.std()\n","    pad = np.pad(arr, 1, mode=\"edge\")\n","    lap = (pad[:-2,1:-1] + pad[2:,1:-1] + pad[1:-1,:-2] + pad[1:-1,2:] - 4*arr)\n","    sharp = float(lap.var())\n","\n","    flags = []\n","    if bright < 70:  flags.append(\"low_light\")\n","    if bright > 200: flags.append(\"overexposed\")\n","    if contrast < 20:flags.append(\"low_contrast\")\n","    if sharp < 80:   flags.append(\"blurry\")\n","    stats = dict(bright=round(float(bright),1), contrast=round(float(contrast),1), sharp=round(sharp,1))\n","    return flags, stats\n","\n","def quality_tips(flags):\n","    tips = []\n","    if \"low_light\" in flags:   tips.append(\"Снимай при дневном свете или включи вспышку.\")\n","    if \"overexposed\" in flags: tips.append(\"Убери блики: смени угол или отойди на 30–50 см.\")\n","    if \"low_contrast\" in flags:tips.append(\"Подойди ближе — заполни кадр машиной.\")\n","    if \"blurry\" in flags:      tips.append(\"Дай автофокусу сработать: задержи телефон на 1 секунду.\")\n","    return tips\n","\n","COLOR_MAP = {\n","    \"scratch\": (255,   0,   0),\n","    \"dent\":    (255, 140,   0),\n","    \"rust\":    (255, 215,   0),\n","    \"car\":     (  0, 255,   0),\n","}\n","\n","def draw_label(draw: ImageDraw.ImageDraw, xy, text, color):\n","    x1,y1,x2,y2 = xy\n","    try:\n","        font = ImageFont.load_default()\n","        tw = int(draw.textlength(text, font=font))\n","        th = 12\n","    except:\n","        font = None\n","        tw, th = 60, 12\n","    pad = 2\n","    bx2 = x1 + tw + pad*2\n","    by2 = y1 + th + pad*2\n","    draw.rectangle([x1, y1, bx2, by2], fill=color)\n","    draw.text((x1+pad, y1+pad), text, fill=(0,0,0), font=font)\n","\n","def _run_detector(detector, img: Image.Image, conf_thr=0.35, names_map=None):\n","    if detector is None:\n","        return []\n","    res = detector.predict(source=img, imgsz=640, conf=conf_thr, verbose=False)\n","    out = []\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","            score = float(b.conf.item())\n","            cls_id = int(b.cls.item()) if hasattr(b, \"cls\") else -1\n","            raw_name = None\n","            if isinstance(names_map, dict):\n","                raw_name = names_map.get(cls_id, str(cls_id))\n","            out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"cls\":cls_id, \"raw_name\": raw_name})\n","    return out\n","\n","def detect_damage(img: Image.Image, conf_thr=0.35):\n","    # Объединяем боксы от двух моделей\n","    boxes_all = []\n","    boxes_all += _run_detector(damage_yolo1, img, conf_thr, names_map=damage_names1)\n","    boxes_all += _run_detector(damage_yolo2, img, conf_thr, names_map=None)\n","\n","    vis = img.copy()\n","    draw = ImageDraw.Draw(vis)\n","    boxes_out = []\n","    for b in boxes_all:\n","        x1,y1,x2,y2 = b[\"xyxy\"]\n","        score = b[\"score\"]\n","        raw = b.get(\"raw_name\", \"damage\")\n","        label = normalize_label(raw)\n","        ru = RU_LABEL.get(label, label)\n","        color = COLOR_MAP.get(label, (0, 200, 255))\n","        draw.rectangle([x1,y1,x2,y2], width=3, outline=color)\n","        draw_label(draw, (x1,y1,x2,y2), f\"{ru} {score:.2f}\", color)\n","        boxes_out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"label\":label})\n","    return boxes_out, vis\n","\n","def compute_counts(dmg_boxes):\n","    counts = {}\n","    for b in dmg_boxes:\n","        lbl = b[\"label\"]\n","        if lbl == \"car\":\n","            continue\n","        counts[lbl] = counts.get(lbl, 0) + 1\n","    return counts\n","\n","def final_status(cleanliness, dmg_boxes, qflags):\n","    if any(b[\"label\"] in (\"scratch\",\"dent\",\"rust\") for b in dmg_boxes):\n","        return \"❌ повреждена — требуется осмотр\"\n","    if \"blurry\" in qflags or \"low_light\" in qflags:\n","        return \"⚠️ низкое качество — сделайте новое фото\"\n","    if cleanliness == \"dirty\":\n","        return \"⚠️ нужна мойка\"\n","    return \"✅ ок — готово\"\n","\n","def health_score(cleanliness, dmg_counts, qflags):\n","    score = 100\n","    score -= 12 * sum(dmg_counts.values())\n","    if cleanliness == \"dirty\": score -= 10\n","    score -= 5 * len(qflags)\n","    score = int(max(0, min(100, score)))\n","    return score\n","\n","def acceptable(status):\n","    # допустимо к размещению, если «ок» или только «нужна мойка»\n","    return status.startswith(\"✅\") or status.startswith(\"⚠️ нужна мойка\")\n","\n","def counts_ru_text(counts_ru: dict) -> str:\n","    if not counts_ru:\n","        return \"Нет выявленных дефектов.\"\n","    lines = [f\"- {k}: {v}\" for k, v in counts_ru.items()]\n","    return \"\\n\".join(lines)\n","\n","def predict(image: Image.Image, use_yolo_crop: bool, conf_thr: float):\n","    if image is None:\n","        return {\"error\":\"Загрузите фото\"}, None, None, None, None, None, None, None, None, None\n","    img = image.convert(\"RGB\")\n","    cropped = crop_car(img) if use_yolo_crop else img\n","\n","    qflags, qstats = quality_flags(cropped)\n","    tips = quality_tips(qflags)\n","    clean_label, clean_scores = clip_cleanliness(cropped)\n","    dmg_boxes, vis = detect_damage(cropped, conf_thr=conf_thr)\n","\n","    damage_label = \"damaged\" if any(b[\"label\"] in (\"scratch\",\"dent\",\"rust\") for b in dmg_boxes) else \"undamaged\"\n","    counts_en = compute_counts(dmg_boxes)\n","    counts_ru = {RU_LABEL.get(k, k): v for k, v in counts_en.items()}\n","    counts_ru_md = counts_ru_text(counts_ru)\n","\n","    score = health_score(clean_label, counts_en, qflags)\n","    status = final_status(clean_label, dmg_boxes, qflags)\n","    acceptable_flag = acceptable(status)\n","\n","    report = {\n","        \"status\": status,\n","        \"acceptable_for_listing\": acceptable_flag,\n","        \"health_score\": score,\n","        \"cleanliness\": clean_label,          # 'clean' | 'dirty'\n","        \"damage\": damage_label,              # 'damaged' | 'undamaged'\n","        \"damage_counts\": counts_en,          # англ. ключи (для интеграции)\n","        \"damage_counts_ru\": counts_ru,       # для UI/питча\n","        \"damage_boxes\": dmg_boxes,\n","        \"quality_flags\": qflags,\n","        \"quality_stats\": qstats,\n","        \"quality_tips\": tips\n","    }\n","    tips_text = (\"• \" + \"\\n• \".join(tips)) if tips else \"—\"\n","    return report, vis, (\"чистая\" if clean_label==\"clean\" else \"грязная\"), \\\n","           (\"повреждена\" if damage_label==\"damaged\" else \"без повреждений\"), \\\n","           status, counts_ru, counts_ru_md, score, tips_text, acceptable_flag\n","\n","# UI модуль\n","with gr.Blocks() as demo:\n","    gr.Markdown(\"# Оценка состояния автомобиля для inDrive\")\n","    gr.Markdown(\"\")\n","\n","    with gr.Row():\n","        with gr.Column():\n","            in_img   = gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля\")\n","            usecrop  = gr.Checkbox(value=True, label=\"Кропнуть авто (YOLO)\")\n","            conf     = gr.Slider(0.1, 0.7, value=0.35, step=0.05, label=\"Порог уверенности повреждений\")\n","            with gr.Row():\n","                with gr.Column(scale=1):\n","                    btn_aggr = gr.Button(\"Агрессивный (0.25)\")\n","                with gr.Column(scale=1):\n","                    btn_bal  = gr.Button(\"Сбалансированный (0.35)\")\n","                with gr.Column(scale=1):\n","                    btn_cons = gr.Button(\"Консервативный (0.45)\")\n","            btn      = gr.Button(\"Анализ\")\n","        with gr.Column():\n","            out_json = gr.JSON(label=\"Отчёт (JSON)\")\n","            save_btn  = gr.Button(\"Скачать JSON\")\n","            save_file = gr.File(label=\"Файл отчёта\")\n","            out_img  = gr.Image(label=\"Кадр с боксами\")\n","            clean_txt= gr.Textbox(label=\"Чистота\", interactive=False)\n","            dmg_txt  = gr.Textbox(label=\"Повреждения\", interactive=False)\n","            status   = gr.Textbox(label=\"Итоговый статус\", interactive=False)\n","            counts_j = gr.JSON(label=\"Счётчик дефектов (JSON, РУС)\")\n","            counts_md= gr.Markdown(\"—\")\n","            score_ui = gr.Slider(0, 100, value=100, step=1, label=\"Индекс состояния (0–100)\", interactive=False)\n","            tips_md  = gr.Markdown(\"Подсказки по качеству появятся здесь\")\n","            ok_flag  = gr.Checkbox(value=False, label=\"Готово к размещению\", interactive=False)\n","\n","    # Основная кнопка\n","    btn.click(\n","        predict,\n","        inputs=[in_img, usecrop, conf],\n","        outputs=[out_json, out_img, clean_txt, dmg_txt, status, counts_j, counts_md, score_ui, tips_md, ok_flag]\n","    )\n","\n","    # Пресеты порогов\n","    btn_aggr.click(lambda: 0.25, outputs=[conf])\n","    btn_bal.click(lambda: 0.35, outputs=[conf])\n","    btn_cons.click(lambda: 0.45, outputs=[conf])\n","\n","    # Сохранение отчёта (в Drive)\n","    save_btn.click(save_json_file, inputs=[out_json], outputs=[save_file])\n","\n","    gr.Markdown(\"<div style='opacity:.7;margin-top:10px;font-size:12px'>Сделано с любовью от команды <b>DOGS</b> для inDrive</div>\")\n","\n","if __name__ == \"__main__\":\n","    demo.launch(server_name=\"0.0.0.0\", server_port=7861, share=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":643,"referenced_widgets":["de793d7a670940968c86ccd0bb948717","36b915e385b647b898606c5c1b81c328","ecbebcdfba2d4b67af23937154da3671","0cf6b8e8d9ae4e2095e0c2645171bc62","8e1b70428ec94a4fabe866c7ff7ba49c","4fe8655da942462eb374a5579d02ffde","0b798b2e359f4e85b366c6d580f37359","fa1b86d181ce49149ed3abe56e1c64a8","bac669ba23b9471b9987d167875fc054","9386be75560b45619bdfa8bc7ecbd5db","c08c133c99a847f8b4f6f42f4a0cea94"]},"id":"pni0nJ6itYJ1","executionInfo":{"status":"ok","timestamp":1757861982278,"user_tz":-300,"elapsed":6830,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"f1ea2cd9-f75f-4d86-82eb-3d5384a489c5"},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":["Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de793d7a670940968c86ccd0bb948717"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://a546426479aaeef207.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://a546426479aaeef207.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}}]},{"cell_type":"code","source":["# %%writefile /content/drive/MyDrive/indrive_hack/app.py\n","import os\n","import gradio as gr\n","from PIL import Image, ImageDraw, ImageFont\n","import torch\n","from transformers import CLIPProcessor, CLIPModel\n","import numpy as np\n","\n","# ПУТИ (для сохранений на Drive) ----------\n","DRIVE_ROOT = \"/content/drive/MyDrive/indrive_hack\"\n","DRIVE_WEI  = f\"{DRIVE_ROOT}/weights\"\n","DRIVE_REP  = f\"{DRIVE_ROOT}/reports\"\n","os.makedirs(DRIVE_REP, exist_ok=True)\n","# ---------------------------------------------------\n","\n","# Сохранение отчета в JSON (теперь на Drive)\n","def save_json_file(report):\n","    import json, time\n","    name = f\"report_{int(time.time())}.json\"\n","    path = os.path.join(DRIVE_REP, name)\n","    with open(path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(report, f, indent=2, ensure_ascii=False)\n","    return path\n","\n","# 1) YOLO для кропа авто (COCO)\n","crop_yolo = None\n","try:\n","    from ultralytics import YOLO\n","    crop_yolo = YOLO(\"yolov8n.pt\")\n","except Exception:\n","    crop_yolo = None\n","\n","# 2) YOLO для повреждений — ОСНОВНЫЕ ВЕСА + ВТОРАЯ МОДЕЛЬ (ищем и в /content/weights, и на Drive)\n","def _first_existing(*paths):\n","    for p in paths:\n","        if p and os.path.exists(p):\n","            return p\n","    return None\n","\n","damage_yolo = None        # первая модель (как у тебя было)\n","damage_names = None\n","damage_yolo2 = None       # ВТОРАЯ модель (новое)\n","\n","# первая модель — как раньше\n","p1 = _first_existing(\n","    \"/content/weights/damage.pt\",\n","    f\"{DRIVE_WEI}/damage.pt\",\n","    \"/content/weights/damage_rust.pt\",\n","    f\"{DRIVE_WEI}/damage_rust.pt\",\n",")\n","\n","# вторая модель — например damage_v2.pt\n","p2 = _first_existing(\n","    \"/content/weights/damage_v2.pt\",\n","    f\"{DRIVE_WEI}/damage_v2.pt\",\n",")\n","\n","try:\n","    from ultralytics import YOLO\n","    if p1:\n","        damage_yolo = YOLO(p1)\n","        try:\n","            damage_names = damage_yolo.model.names if hasattr(damage_yolo, \"model\") else damage_yolo.names\n","        except Exception:\n","            damage_names = None\n","    if p2:\n","        damage_yolo2 = YOLO(p2)\n","except Exception:\n","    damage_yolo = None\n","    damage_yolo2 = None\n","    damage_names = None\n","\n","# Нормализация кривых меток\n","def normalize_label(name: str) -> str:\n","    n = str(name).lower()\n","    if n == \"dunt\":    return \"dent\"\n","    if n == \"scracth\": return \"scratch\"\n","    return n\n","\n","# Русские подписи классов\n","RU_LABEL = {\n","    \"scratch\": \"царапина\",\n","    \"dent\":    \"вмятина\",\n","    \"rust\":    \"ржавчина\",\n","    \"car\":     \"авто\",\n","}\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n","clip_proc  = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","cleanliness_texts = [\"a clean car photo\",\"a dirty, muddy car photo\"]\n","\n","def crop_car(img: Image.Image) -> Image.Image:\n","    if crop_yolo is None:\n","        return img\n","    res = crop_yolo.predict(source=img, imgsz=640, conf=0.25, verbose=False)\n","    if not res: return img\n","    best_area, best_box = 0, None\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            try:\n","                if int(b.cls.item()) != 2:  # 2 = 'car' в COCO\n","                    continue\n","                x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","                area = (x2-x1)*(y2-y1)\n","                if area > best_area:\n","                    best_area, best_box = area, (x1,y1,x2,y2)\n","            except:\n","                pass\n","    if best_box is None: return img\n","    x1,y1,x2,y2 = best_box\n","    x1=max(0,x1); y1=max(0,y1); x2=min(img.width,x2); y2=min(img.height,y2)\n","    return img.crop((x1,y1,x2,y2)) if x2>x1 and y2>y1 else img\n","\n","@torch.no_grad()\n","def clip_cleanliness(img: Image.Image):\n","    inputs = clip_proc(text=cleanliness_texts, images=img, return_tensors=\"pt\", padding=True).to(device)\n","    probs = clip_model(**inputs).logits_per_image[0].softmax(dim=0).detach().cpu().numpy()\n","    idx = int(np.argmax(probs))\n","    return [\"clean\",\"dirty\"][idx], {t: float(p) for t,p in zip(cleanliness_texts, probs)}\n","\n","def quality_flags(img: Image.Image):\n","    # Оценка качества кадра\n","    arr = np.array(img.convert(\"L\"))\n","    bright = arr.mean()\n","    contrast = arr.std()\n","    pad = np.pad(arr, 1, mode=\"edge\")\n","    lap = (pad[:-2,1:-1] + pad[2:,1:-1] + pad[1:-1,:-2] + pad[1:-1,2:] - 4*arr)\n","    sharp = float(lap.var())\n","\n","    flags = []\n","    if bright < 70:  flags.append(\"low_light\")\n","    if bright > 200: flags.append(\"overexposed\")\n","    if contrast < 20:flags.append(\"low_contrast\")\n","    if sharp < 80:   flags.append(\"blurry\")\n","    stats = dict(bright=round(float(bright),1), contrast=round(float(contrast),1), sharp=round(sharp,1))\n","    return flags, stats\n","\n","def quality_tips(flags):\n","    tips = []\n","    if \"low_light\" in flags:   tips.append(\"Фото тёмное — попробуй днём или включи вспышку, так будет чётче.\")\n","    if \"overexposed\" in flags: tips.append(\"Слишком ярко, есть блики. Сними под другим углом или отойди на 30–50 см.\")\n","    if \"low_contrast\" in flags:tips.append(\"Кадр пустоват — подойди ближе, чтобы машина полностью попала в фото.\")\n","    if \"blurry\" in flags:      tips.append(\"Картинка размытая — дай камере секунду сфокусироваться.\")\n","    return tips\n","\n","COLOR_MAP = {\n","    \"scratch\": (255,   0,   0),\n","    \"dent\":    (255, 140,   0),\n","    \"rust\":    (255, 215,   0),\n","    \"car\":     (  0, 255,   0),\n","}\n","\n","def draw_label(draw: ImageDraw.ImageDraw, xy, text, color):\n","    x1,y1,x2,y2 = xy\n","    try:\n","        font = ImageFont.load_default()\n","        tw = int(draw.textlength(text, font=font))\n","        th = 12\n","    except:\n","        font = None\n","        tw, th = 60, 12\n","    pad = 2\n","    bx2 = x1 + tw + pad*2\n","    by2 = y1 + th + pad*2\n","    draw.rectangle([x1, y1, bx2, by2], fill=color)\n","    draw.text((x1+pad, y1+pad), text, fill=(0,0,0), font=font)\n","\n","def run_detector(detector, img: Image.Image, conf_thr=0.35, names_map=None):\n","    if detector is None:\n","        return []\n","    res = detector.predict(source=img, imgsz=640, conf=conf_thr, verbose=False)\n","    out = []\n","    for r in res:\n","        if r.boxes is None: continue\n","        for b in r.boxes:\n","            x1,y1,x2,y2 = map(int, b.xyxy[0].tolist())\n","            score = float(b.conf.item())\n","            cls_id = int(b.cls.item()) if hasattr(b, \"cls\") else -1\n","            raw_name = names_map.get(cls_id, str(cls_id)) if isinstance(names_map, dict) else str(cls_id)\n","            out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"cls\":cls_id, \"raw_name\": raw_name})\n","    return out\n","\n","def detect_damage(img: Image.Image, conf_thr=0.35):\n","    # Объединяем результаты от двух моделей\n","    boxes_all = []\n","    boxes_all += run_detector(damage_yolo,  img, conf_thr, names_map=damage_names)\n","    boxes_all += run_detector(damage_yolo2, img, conf_thr, names_map=None)\n","\n","    vis = img.copy()\n","    draw = ImageDraw.Draw(vis)\n","    boxes_out = []\n","    for b in boxes_all:\n","        x1,y1,x2,y2 = b[\"xyxy\"]\n","        score = b[\"score\"]\n","        label = normalize_label(b.get(\"raw_name\",\"damage\"))\n","        ru = RU_LABEL.get(label, label)\n","        color = COLOR_MAP.get(label, (0, 200, 255))\n","        draw.rectangle([x1,y1,x2,y2], width=3, outline=color)\n","        draw_label(draw, (x1,y1,x2,y2), f\"{ru} {score:.2f}\", color)\n","        boxes_out.append({\"xyxy\":[x1,y1,x2,y2], \"score\":score, \"label\":label})\n","    return boxes_out, vis\n","\n","def compute_counts(dmg_boxes):\n","    counts = {}\n","    for b in dmg_boxes:\n","        lbl = b[\"label\"]\n","        if lbl == \"car\":\n","            continue\n","        counts[lbl] = counts.get(lbl, 0) + 1\n","    return counts\n","\n","def final_status(cleanliness, dmg_boxes, qflags):\n","    if any(b[\"label\"] in (\"scratch\",\"dent\",\"rust\") for b in dmg_boxes):\n","        return \"❌ Замечены повреждения — стоит обратить внимание.\"\n","    if \"blurry\" in qflags or \"low_light\" in qflags:\n","        return \"⚠️ Фото смазанное или тёмное — лучше сделать ещё одно.\"\n","    if cleanliness == \"dirty\":\n","        return \"⚠️ Машина выглядит грязной — для более точного результата можно её протереть или заехать на мойку.\"\n","    return \"✅ Всё хорошо — фото принято.\"\n","\n","def health_score(cleanliness, dmg_counts, qflags):\n","    score = 100\n","    score -= 12 * sum(dmg_counts.values())\n","    if cleanliness == \"dirty\": score -= 10\n","    score -= 5 * len(qflags)\n","    score = int(max(0, min(100, score)))\n","    return score\n","\n","def acceptable(status):\n","    # Допустимо к размещению, если \"Всё хорошо\" или вариант \"грязная\" без других проблем\n","    return status.startswith(\"✅\") or (\"грязн\" in status.lower())\n","\n","def counts_ru_text(counts_ru: dict) -> str:\n","    if not counts_ru:\n","        return \"Нет выявленных дефектов\"\n","    lines = [f\"- {k}: {v}\" for k, v in counts_ru.items()]\n","    return \"\\n\".join(lines)\n","\n","def predict(image: Image.Image, use_yolo_crop: bool, conf_thr: float):\n","    if image is None:\n","        return {\"error\":\"Загрузите фото\"}, None, None, None, None, None, None, None, None, None\n","    img = image.convert(\"RGB\")\n","    cropped = crop_car(img) if use_yolo_crop else img\n","\n","    qflags, qstats = quality_flags(cropped)\n","    tips = quality_tips(qflags)\n","    clean_label, clean_scores = clip_cleanliness(cropped)\n","    dmg_boxes, vis = detect_damage(cropped, conf_thr=conf_thr)\n","\n","    damage_label = \"damaged\" if any(b[\"label\"] in (\"scratch\",\"dent\",\"rust\") for b in dmg_boxes) else \"undamaged\"\n","    counts_en = compute_counts(dmg_boxes)\n","    counts_ru = {RU_LABEL.get(k, k): v for k, v in counts_en.items()}\n","    counts_ru_md = counts_ru_text(counts_ru)\n","    counts_display = {\"всего\": int(sum(counts_en.values())), \"по типам\": counts_ru}\n","\n","    score = health_score(clean_label, counts_en, qflags)\n","    status = final_status(clean_label, dmg_boxes, qflags)\n","    acceptable_flag = acceptable(status)\n","\n","    report = {\n","        \"status\": status,\n","        \"acceptable_for_listing\": acceptable_flag,\n","        \"health_score\": score,\n","        \"cleanliness\": clean_label,          # \"clean\"   | \"dirty\"\n","        \"damage\": damage_label,              # \"damaged\" | \"undamaged\"\n","        \"damage_counts\": counts_en,          # англ. ключи (для интеграции)\n","        \"damage_counts_ru\": counts_ru,\n","        \"damage_boxes\": dmg_boxes,\n","        \"quality_flags\": qflags,\n","        \"quality_stats\": qstats,\n","        \"quality_tips\": tips\n","    }\n","    tips_text = (\"• \" + \"\\n• \".join(tips)) if tips else \"—\"\n","    clean_ru = \"Чистая\" if clean_label.lower()==\"clean\" else \"Грязная\"\n","    dmg_ru   = \"Повреждена\" if damage_label.lower()==\"damaged\" else \"Без повреждений\"\n","\n","    return report, vis, clean_ru, dmg_ru, status, counts_display, counts_ru_md, score, tips_text, acceptable_flag\n","\n","# UI блок\n","with gr.Blocks() as demo:\n","    gr.Markdown(\"**Оценка состояния автомобиля для inDrive**\")\n","    gr.Markdown(\"Загрузите фото: нейросеть проверит чистоту, найдёт повреждения и подскажет результат.\")\n","\n","    with gr.Row():\n","        with gr.Column():\n","            in_img   = gr.Image(type=\"pil\", label=\"Загрузите фото автомобиля\")\n","            usecrop  = gr.Checkbox(value=True, label=\"Кропать авто (YOLO)\")\n","            conf     = gr.Slider(0.1, 0.7, value=0.35, step=0.05, label=\"Порог уверенности повреждений\")\n","            with gr.Row(equal_height=True):\n","                btn_aggr = gr.Button(\"Агрессивный (0.25)\")\n","                btn_bal  = gr.Button(\"Сбалансированный (0.35)\")\n","                btn_cons = gr.Button(\"Консервативный (0.45)\")\n","            btn      = gr.Button(\"Анализ\")\n","        with gr.Column():\n","            out_json = gr.JSON(label=\"Отчет (JSON)\")\n","            save_btn  = gr.Button(\"Скачать JSON\")\n","            save_file = gr.File(label=\"Файл отчета\")\n","            out_img  = gr.Image(label=\"Кадр с боксами\")\n","            clean_txt= gr.Textbox(label=\"Чистота\", interactive=False)\n","            dmg_txt  = gr.Textbox(label=\"Повреждения\", interactive=False)\n","            status   = gr.Textbox(label=\"Итоговый статус\", interactive=False)\n","            counts_j = gr.JSON(label=\"Счетчик дефектов\")\n","            counts_md= gr.Markdown(\"—\")\n","            score_ui = gr.Slider(0, 100, value=100, step=1, label=\"Индекс состояния (0–100)\", interactive=False)\n","            tips_md  = gr.Markdown(\"Подсказки по качеству появятся здесь\")\n","            ok_flag  = gr.Checkbox(value=False, label=\"Готово к размещению\", interactive=False)\n","\n","    # Основная кнопка\n","    btn.click(\n","        predict,\n","        inputs=[in_img, usecrop, conf],\n","        outputs=[out_json, out_img, clean_txt, dmg_txt, status, counts_j, counts_md, score_ui, tips_md, ok_flag]\n","    )\n","\n","    # Пресеты порогов\n","    btn_aggr.click(lambda: 0.25, outputs=[conf])\n","    btn_bal.click(lambda: 0.35, outputs=[conf])\n","    btn_cons.click(lambda: 0.45, outputs=[conf])\n","\n","    # Сохранение отчета (на Drive)\n","    save_btn.click(save_json_file, inputs=[out_json], outputs=[save_file])\n","\n","    # --- Подвал с подписью (новое) ---\n","    gr.Markdown(\"<div style='opacity:.7;margin-top:10px;font-size:12px'>Сделано с любовью от команды <b>DOGS</b> для inDrive</div>\")\n","\n","if __name__ == \"__main__\":\n","    # На случай занятого порта\n","    try:\n","        gr.close_all()\n","    except Exception:\n","        pass\n","    try:\n","        demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True)\n","    except OSError:\n","        demo.launch(server_name=\"0.0.0.0\", share=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":678,"referenced_widgets":["019a5fd1f07b4481b91a45cefd3758c4","6cb5ef1bf7e04af8a46ac78b06907ad1","55d602182c8e46ef9b97c37bba2a1db9","b784fe5a71404637a66658f2472fdfae","c74a08d74f914558afc44e29ff8c8407","6a584f0350344c76a8e165b6839b1600","3a0c7b5a1f784387a2236cdf35bde7e0","dca9dccd133443a7846997ac12b91c7f","b753e069af244dd3b976e66551220ebc","cbd93927e8cf412d9bcbd5be9e863ea9","0c1f60cf678b451b84b859fb63b3fff6"]},"id":"XLc1qTpPyga3","executionInfo":{"status":"ok","timestamp":1757862845383,"user_tz":-300,"elapsed":7581,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"30d3d959-3026-4304-a01f-8b2c814ace13"},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":["Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"019a5fd1f07b4481b91a45cefd3758c4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Closing server running on port: 7860\n","Closing server running on port: 7861\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://f04bcd9258c2a77c24.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://f04bcd9258c2a77c24.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}}]},{"cell_type":"code","source":["!ls -lh /content/drive/MyDrive/indrive_hack/weights\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrsqAE3t88fl","executionInfo":{"status":"ok","timestamp":1757865563019,"user_tz":-300,"elapsed":179,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"575b9d57-7008-40a9-92ba-be38d9b120e1"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["total 44M\n","-rw------- 1 root root 22M Sep 14 13:09 damage_rust.pt\n","-rw------- 1 root root 22M Sep 14 13:16 damage_v2.pt\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-WzyqgwxCh7p","executionInfo":{"status":"ok","timestamp":1757867032930,"user_tz":-300,"elapsed":6100,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"dd863250-638d-4805-b6f0-ffa819783ef0"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Вся ячейка = bash\n","%%bash\n","cd /content\n","rm -rf indrive-auto-health\n","git clone https://github.com/dudlextop/indrive-auto-health.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YSTFT7DmD9wN","executionInfo":{"status":"ok","timestamp":1757867409743,"user_tz":-300,"elapsed":1293,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"94d5b1d0-3d15-44c3-f998-330864a92212"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["Cloning into 'indrive-auto-health'...\n"]}]},{"cell_type":"code","source":["# перейти в папку репозитория\n","%cd /content/indrive-auto-health\n","!ls -la\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1XQvvrdECgu","executionInfo":{"status":"ok","timestamp":1757867423598,"user_tz":-300,"elapsed":224,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"7842c744-d4ec-491c-d39e-4820020f7b34"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/indrive-auto-health\n","total 44\n","drwxr-xr-x 3 root root  4096 Sep 14 16:30 .\n","drwxr-xr-x 1 root root  4096 Sep 14 16:30 ..\n","-rw-r--r-- 1 root root 12337 Sep 14 16:30 app.py\n","drwxr-xr-x 8 root root  4096 Sep 14 16:30 .git\n","-rw-r--r-- 1 root root   128 Sep 14 16:30 .gitignore\n","-rw-r--r-- 1 root root    48 Sep 14 16:30 README.md\n","-rw-r--r-- 1 root root   147 Sep 14 16:30 requirements.txt\n","-rw-r--r-- 1 root root   754 Sep 14 16:30 theme.css\n"]}]},{"cell_type":"code","source":["# Убедимся, что папка weights есть\n","!mkdir -p /content/indrive-auto-health/weights\n","\n","# Копируем оба файла весов из твоего Drive\n","!cp -v /content/drive/MyDrive/indrive_hack/weights/damage_rust.pt /content/indrive-auto-health/weights/\n","!cp -v /content/drive/MyDrive/indrive_hack/weights/damage_v2.pt   /content/indrive-auto-health/weights/\n","\n","# Проверим\n","!ls -lh /content/indrive-auto-health/weights\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BtYjQIJ0EJbQ","executionInfo":{"status":"ok","timestamp":1757867451679,"user_tz":-300,"elapsed":674,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"1575e150-5c5d-40fa-a444-3e36e88db51d"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["'/content/drive/MyDrive/indrive_hack/weights/damage_rust.pt' -> '/content/indrive-auto-health/weights/damage_rust.pt'\n","'/content/drive/MyDrive/indrive_hack/weights/damage_v2.pt' -> '/content/indrive-auto-health/weights/damage_v2.pt'\n","total 44M\n","-rw------- 1 root root 22M Sep 14 16:30 damage_rust.pt\n","-rw------- 1 root root 22M Sep 14 16:30 damage_v2.pt\n"]}]},{"cell_type":"code","source":["# настроим имя и email для коммита (любые твои)\n","!git config user.name \"dudlextop\"\n","!git config user.email \"dudlextoppartnership@gmail.com\"\n","\n","# добавить файлы\n","!git add weights/damage_rust.pt weights/damage_v2.pt\n","!git commit -m \"Add YOLO weights: damage_rust.pt and damage_v2.pt\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nR2_80n9ELVp","executionInfo":{"status":"ok","timestamp":1757867503003,"user_tz":-300,"elapsed":551,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"452f03f4-1dc0-4a67-e083-88fb23b74e2a"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["The following paths are ignored by one of your .gitignore files:\n","weights\n","\u001b[33mhint: Use -f if you really want to add them.\u001b[m\n","\u001b[33mhint: Turn this message off by running\u001b[m\n","\u001b[33mhint: \"git config advice.addIgnoredFile false\"\u001b[m\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n"]}]},{"cell_type":"code","source":["# откроем gitignore\n","!nano .gitignore\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejIvmLg4F8eB","executionInfo":{"status":"ok","timestamp":1757867925431,"user_tz":-300,"elapsed":154,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"ce0a67f6-ce47-4590-8fea-82d83ad97862"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nano: command not found\n"]}]},{"cell_type":"code","source":["!cat > .gitignore <<EOL\n","# Python\n","__pycache__/\n","*.pyc\n","\n","# Weights and runs\n","runs/\n","\n","# Игнорировать все pt кроме нужных\n","*.pt\n","!weights/damage_rust.pt\n","!weights/damage_v2.pt\n","\n","# Colab / notebooks noise\n",".ipynb_checkpoints/\n","*.checkpoint\n","EOL\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"cZJkL2iLGkHb","executionInfo":{"status":"error","timestamp":1757868084835,"user_tz":-300,"elapsed":318,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"209c268d-76f3-4aed-cbb0-dc77b6352bf7"},"execution_count":40,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (ipython-input-883205243.py, line 3)","traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-883205243.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    __pycache__/\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["%%writefile .gitignore\n","# Python\n","__pycache__/\n","*.pyc\n","\n","# Weights and runs\n","runs/\n","\n","# Игнорировать все pt кроме нужных\n","*.pt\n","!weights/damage_rust.pt\n","!weights/damage_v2.pt\n","\n","# Colab / notebooks noise\n",".ipynb_checkpoints/\n","*.checkpoint\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ThwACph1G5EK","executionInfo":{"status":"ok","timestamp":1757868170855,"user_tz":-300,"elapsed":16,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"40da1e39-9671-4dab-ca4f-f89f7b0d7072"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting .gitignore\n"]}]},{"cell_type":"code","source":["!cat .gitignore\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"624cT7V7G7AR","executionInfo":{"status":"ok","timestamp":1757868191074,"user_tz":-300,"elapsed":298,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"98f2c7d9-1c0e-4675-c35c-237128b7a938"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["# Python\n","__pycache__/\n","*.pyc\n","\n","# Weights and runs\n","runs/\n","\n","# Игнорировать все pt кроме нужных\n","*.pt\n","!weights/damage_rust.pt\n","!weights/damage_v2.pt\n","\n","# Colab / notebooks noise\n",".ipynb_checkpoints/\n","*.checkpoint\n"]}]},{"cell_type":"code","source":["!git add weights/damage_rust.pt weights/damage_v2.pt\n"],"metadata":{"id":"_wZEslyLHNWl","executionInfo":{"status":"ok","timestamp":1757868256794,"user_tz":-300,"elapsed":2922,"user":{"displayName":"Alex","userId":"01492490224081509670"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"Add YOLO weights: damage_rust.pt и damage_v2.pt\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZpbVtZAHQI5","executionInfo":{"status":"ok","timestamp":1757868269664,"user_tz":-300,"elapsed":178,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"a7979694-67c2-41e7-c6b3-33874c2fa2a8"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["[main c16ca64] Add YOLO weights: damage_rust.pt и damage_v2.pt\n"," 2 files changed, 0 insertions(+), 0 deletions(-)\n"," create mode 100644 weights/damage_rust.pt\n"," create mode 100644 weights/damage_v2.pt\n"]}]},{"cell_type":"code","source":["!git push origin main\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0fQIekRHS6y","executionInfo":{"status":"ok","timestamp":1757868286827,"user_tz":-300,"elapsed":443,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"4204f0d5-ac07-4712-c1f1-1f7b399d2543"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: could not read Username for 'https://github.com': No such device or address\n"]}]},{"cell_type":"code","source":["USER = \"dudlextop\"                # ваш логин GitHub\n","REPO = \"indrive-auto-health\"      # имя репозитория\n","TOKEN = \"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\"    # ВСТАВЬТЕ НОВЫЙ ТОКЕН\n","\n","# Меняем origin на https с токеном\n","!git remote set-url origin https://{USER}:{TOKEN}@github.com/{USER}/{REPO}.git\n","!git remote -v\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IIX5hVrqIRAD","executionInfo":{"status":"ok","timestamp":1757868545070,"user_tz":-300,"elapsed":349,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"a9b82ef2-8d9b-472c-aea9-a3292b345e6a"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["origin\thttps://dudlextop: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@github.com/dudlextop/indrive-auto-health.git (fetch)\n","origin\thttps://dudlextop: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@github.com/dudlextop/indrive-auto-health.git (push)\n"]}]},{"cell_type":"code","source":["!git push origin main\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kxt8PNv4IZvy","executionInfo":{"status":"ok","timestamp":1757868566842,"user_tz":-300,"elapsed":751,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"d7279b3c-cebc-43eb-8b0a-f74a15cb5d8c"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["To https://github.com/dudlextop/indrive-auto-health.git\n"," \u001b[31m! [rejected]       \u001b[m main -> main (fetch first)\n","\u001b[31merror: failed to push some refs to 'https://github.com/dudlextop/indrive-auto-health.git'\n","\u001b[m\u001b[33mhint: Updates were rejected because the remote contains work that you do\u001b[m\n","\u001b[33mhint: not have locally. This is usually caused by another repository pushing\u001b[m\n","\u001b[33mhint: to the same ref. You may want to first integrate the remote changes\u001b[m\n","\u001b[33mhint: (e.g., 'git pull ...') before pushing again.\u001b[m\n","\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n"]}]},{"cell_type":"code","source":["!git pull origin main --allow-unrelated-histories\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uI_MjkzWIws4","executionInfo":{"status":"ok","timestamp":1757868661792,"user_tz":-300,"elapsed":1186,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"0d8a2f42-bb8b-4a99-d2d2-1e8d74cdfa68"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Enumerating objects: 5, done.\u001b[K\n","remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n","remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 3 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 1.07 KiB | 1.07 MiB/s, done.\n","From https://github.com/dudlextop/indrive-auto-health\n"," * branch            main       -> FETCH_HEAD\n","   4e74f4b..8dce654  main       -> origin/main\n","\u001b[33mhint: You have divergent branches and need to specify how to reconcile them.\u001b[m\n","\u001b[33mhint: You can do so by running one of the following commands sometime before\u001b[m\n","\u001b[33mhint: your next pull:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint:   git config pull.rebase false  # merge (the default strategy)\u001b[m\n","\u001b[33mhint:   git config pull.rebase true   # rebase\u001b[m\n","\u001b[33mhint:   git config pull.ff only       # fast-forward only\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: You can replace \"git config\" with \"git config --global\" to set a default\u001b[m\n","\u001b[33mhint: preference for all repositories. You can also pass --rebase, --no-rebase,\u001b[m\n","\u001b[33mhint: or --ff-only on the command line to override the configured default per\u001b[m\n","\u001b[33mhint: invocation.\u001b[m\n","fatal: Need to specify how to reconcile divergent branches.\n"]}]},{"cell_type":"code","source":["!git push origin main\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ff-t43amIzdo","executionInfo":{"status":"ok","timestamp":1757868678294,"user_tz":-300,"elapsed":742,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"3d5cc1f8-efca-4806-fb93-48af62167d3b"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["To https://github.com/dudlextop/indrive-auto-health.git\n"," \u001b[31m! [rejected]       \u001b[m main -> main (non-fast-forward)\n","\u001b[31merror: failed to push some refs to 'https://github.com/dudlextop/indrive-auto-health.git'\n","\u001b[m\u001b[33mhint: Updates were rejected because the tip of your current branch is behind\u001b[m\n","\u001b[33mhint: its remote counterpart. Integrate the remote changes (e.g.\u001b[m\n","\u001b[33mhint: 'git pull ...') before pushing again.\u001b[m\n","\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n"]}]},{"cell_type":"code","source":["# 1) Подтягиваем удалённую ветку и накатываем наш коммит поверх (rebase)\n","!git pull --rebase origin main\n","\n","# 2) Пушим\n","!git push origin main\n","\n","# 3) (опционально) возвращаем origin на обычный URL без токена\n","!git remote set-url origin https://github.com/dudlextop/indrive-auto-health.git\n","!git remote -v\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8LmaUXlJzUE","executionInfo":{"status":"ok","timestamp":1757868934025,"user_tz":-300,"elapsed":1039,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"03ffbdc6-08a5-497f-a33e-202df3aea252"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["error: cannot pull with rebase: You have unstaged changes.\n","error: please commit or stash them.\n","To https://github.com/dudlextop/indrive-auto-health.git\n"," \u001b[31m! [rejected]       \u001b[m main -> main (non-fast-forward)\n","\u001b[31merror: failed to push some refs to 'https://github.com/dudlextop/indrive-auto-health.git'\n","\u001b[m\u001b[33mhint: Updates were rejected because the tip of your current branch is behind\u001b[m\n","\u001b[33mhint: its remote counterpart. Integrate the remote changes (e.g.\u001b[m\n","\u001b[33mhint: 'git pull ...') before pushing again.\u001b[m\n","\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n","origin\thttps://github.com/dudlextop/indrive-auto-health.git (fetch)\n","origin\thttps://github.com/dudlextop/indrive-auto-health.git (push)\n"]}]},{"cell_type":"code","source":["!git add -A\n","!git stash\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IWgAHdhTKC1W","executionInfo":{"status":"ok","timestamp":1757868997502,"user_tz":-300,"elapsed":555,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"51554152-f9fd-484e-ab62-78e7b44e4e57"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved working directory and index state WIP on main: c16ca64 Add YOLO weights: damage_rust.pt и damage_v2.pt\n"]}]},{"cell_type":"code","source":["!git pull --rebase origin main\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jt7Z-OnGKGRk","executionInfo":{"status":"ok","timestamp":1757869010913,"user_tz":-300,"elapsed":911,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"df9ed100-b998-4b31-bb1e-6293eec205c0"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["From https://github.com/dudlextop/indrive-auto-health\n"," * branch            main       -> FETCH_HEAD\n","\u001b[KSuccessfully rebased and updated refs/heads/main.\n"]}]},{"cell_type":"code","source":["!git stash pop\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gd23OEdnKLCY","executionInfo":{"status":"ok","timestamp":1757869030447,"user_tz":-300,"elapsed":211,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"2d66bb40-ec76-4150-d17d-b9369f4ace3f"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is ahead of 'origin/main' by 1 commit.\n","  (use \"git push\" to publish your local commits)\n","\n","nothing to commit, working tree clean\n","Dropped refs/stash@{0} (f45167b2f7de7cdf6335c76fd1547e0e73d3c830)\n"]}]},{"cell_type":"code","source":["!git add weights/damage_rust.pt weights/damage_v2.pt\n","!git commit -m \"Add YOLO weights damage_rust.pt и damage_v2.pt\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXlIqRlZKMs9","executionInfo":{"status":"ok","timestamp":1757869041331,"user_tz":-300,"elapsed":272,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"daed20ba-6b90-44ce-aabb-6ff42cd700f2"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is ahead of 'origin/main' by 1 commit.\n","  (use \"git push\" to publish your local commits)\n","\n","nothing to commit, working tree clean\n"]}]},{"cell_type":"code","source":["!git push origin main\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erdbNE7_KRSF","executionInfo":{"status":"ok","timestamp":1757869055699,"user_tz":-300,"elapsed":423,"user":{"displayName":"Alex","userId":"01492490224081509670"}},"outputId":"fb6e55b9-cfde-4e9f-9675-2f96e2a5a5fa"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: could not read Username for 'https://github.com': No such device or address\n"]}]}]}